{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tatiana/opt/anaconda3/lib/python3.7/site-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n",
      "/Users/tatiana/opt/anaconda3/lib/python3.7/site-packages/past/builtins/misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping\n",
      "/Users/tatiana/opt/anaconda3/lib/python3.7/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# topic modeling libraries\n",
    "import pyLDAvis.gensim \n",
    "\n",
    "# data visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# supporting libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import topic_modeling_v6 as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics_1 = 10\n",
    "num_topics_2 = 5\n",
    "num_topics_3 = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get FIRST level of topics (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33982, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['date', 'author', 'title', 'url', 'section', 'publication',\n",
       "       'first_10_sents', 'list_of_first_10_sents', 'list_of_verb_lemmas',\n",
       "       'noun_phrases', 'list_of_nouns', 'list_of_lemmas', 'ID',\n",
       "       'group_level_1', 'group_level_2', 'group_level_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data for LDA\n",
    "df_data = pd.read_csv(\"./data/train_grouped.tsv\", sep=\"\\t\")\n",
    "    \n",
    "print(df_data.shape)\n",
    "df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [rise, economies, march, globalisation, surge,...\n",
       "1    [pfizer, commitment, responsibility, drugs, ta...\n",
       "2    [weeks, interest, rates, time, years, world, b...\n",
       "3    [cruise, lines, wave, months, year, holidays, ...\n",
       "4    [calendar, year, mood, events, consensus, resp...\n",
       "Name: list_of_nouns, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['list_of_nouns'] = df_data['list_of_nouns'].str.lower().str[1:-1].str.split(\", \")\n",
    "df_data['list_of_nouns'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [rise, big, emerging, economies, steady, march...\n",
       "1    [pfizer, prided, commitment, corporate, social...\n",
       "2    [weeks, raised, interest, rates, time, years, ...\n",
       "3    [cruise, lines, brace, wave, months, year, nea...\n",
       "4    [start, calendar, year, buoyant, mood, caught,...\n",
       "Name: list_of_lemmas, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['list_of_lemmas'] = df_data['list_of_lemmas'].str.lower().str[1:-1].str.split(\", \")\n",
    "df_data['list_of_lemmas'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data shape: (33982, 16)\n",
      "\n",
      "Total number of unique Lemmas:  82802\n",
      "\n",
      "Distribution of lemmas' document counts: \n",
      "     count       mean         std  min  50%  55%  65%  75%   85%   95%    97%  \\\n",
      "0  82802.0  26.127642  154.452831  1.0  1.0  2.0  3.0  6.0  17.0  94.0  175.0   \n",
      "\n",
      "     99%      max  \n",
      "0  512.0  11676.0  \n",
      "\n",
      "Deleting too frequent and too rare words...\n",
      "Lemma count upper bound: 512.0\n",
      "Lemma count lower bound: 3\n",
      "\n",
      "List of words for topic modeling dictionary is reduced from 82802 to 26768\n",
      "LDA dictionary file is saved to: ./output/lda/dictionary1.pickle\n",
      "\n",
      "Number of texts processed:  33980\n",
      "Number of extracted lemmas:  26768\n",
      "\n",
      "Each text is represented by list of  26768  tuples: \n",
      "\t\t(lemma's index in bag-of-words dictionary, lemma's term frequency)\n",
      "Processing time in minutes: 0.07\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df_data_1 = tm.prepare_for_modeling(data_path=\"\", model_type=\"LDA\",\n",
    "                                               params={\"TEXT_prepared_df\": df_data,\n",
    "                                                       \"save_LDA_dictionary_path\": \"./output/lda/dictionary1.pickle\"\n",
    "                                                       },\n",
    "                                        verbose=2)\n",
    "end_time = time.time()\n",
    "print(\"Processing time in minutes:\", round((end_time - start_time)/60,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "loaded data shape: (33980, 18)\n",
      "\n",
      "Creating document-term matrix for LDA...\n",
      "\n",
      "Training LDA model with  10  topics...\n",
      "LDA model file is saved to: ./output/lda/LDA_model1\n",
      "Top topic indexes are selected. NOTE \"-1\" corresponds to top topic with probability < 20%\n",
      "Processing time in minutes: 1.61\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df_first_level = tm.train_model(model_type=\"LDA\",\n",
    "                            params={\"num_topics\": num_topics_1,\n",
    "                                    \"LDA_prepared_df\": df_data_1,\n",
    "                                    \"LDA_dictionary_path\": \"./output/lda/dictionary1.pickle\",\n",
    "                                    \"save_LDA_model_path\": \"./output/lda/LDA_model1\"\n",
    "                                    },\n",
    "                               verbose=2)\n",
    "end_time = time.time()\n",
    "print(\"Processing time in minutes:\", round((end_time - start_time)/60,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1457\n",
       "1    4999\n",
       "2    1962\n",
       "3    3133\n",
       "4    2096\n",
       "5    2862\n",
       "6    4345\n",
       "7    6634\n",
       "8    3142\n",
       "9    3350\n",
       "Name: first_level_topic, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value count of TOP level topics\n",
    "df_first_level['first_level_topic'] = df_first_level['top_topic']\n",
    "df_first_level['first_level_topic_proba'] = df_first_level['top_topic_proba']\n",
    "df_first_level['first_level_topic'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_level = df_first_level.drop(columns=['selected_words', 'doc2bow',\n",
    "       'infered_topics', 'top_topic', 'top_topic_proba'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Get SECOND level topics (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_level_topics = list(set(df_first_level['first_level_topic']))\n",
    "first_level_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected topic index: 0\n",
      "loaded data shape: (1457, 18)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_1\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    247\n",
      "1    319\n",
      "2    235\n",
      "3    297\n",
      "4    359\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 1\n",
      "loaded data shape: (4999, 18)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_2\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0     743\n",
      "1    1391\n",
      "2     742\n",
      "3    1078\n",
      "4    1045\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 2\n",
      "loaded data shape: (1962, 18)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_3\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    247\n",
      "1    469\n",
      "2    231\n",
      "3    480\n",
      "4    535\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 3\n",
      "loaded data shape: (3133, 18)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_4\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    560\n",
      "1    875\n",
      "2    619\n",
      "3    384\n",
      "4    695\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 4\n",
      "loaded data shape: (2096, 18)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_5\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    326\n",
      "1    391\n",
      "2    439\n",
      "3    531\n",
      "4    409\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 5\n",
      "loaded data shape: (2862, 18)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_6\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    784\n",
      "1    479\n",
      "2    493\n",
      "3    609\n",
      "4    497\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 6\n",
      "loaded data shape: (4345, 18)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_7\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0     654\n",
      "1    1090\n",
      "2     635\n",
      "3    1129\n",
      "4     837\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 7\n",
      "loaded data shape: (6634, 18)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_8\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    1458\n",
      "1    1258\n",
      "2     906\n",
      "3    1587\n",
      "4    1424\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 8\n",
      "loaded data shape: (3142, 18)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_9\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    606\n",
      "1    566\n",
      "2    818\n",
      "3    647\n",
      "4    505\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 9\n",
      "loaded data shape: (3350, 18)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_10\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    493\n",
      "1    592\n",
      "2    778\n",
      "3    934\n",
      "4    553\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "list_dfs = []\n",
    "for topic in first_level_topics:\n",
    "    print(\"\\nSelected topic index:\", topic)\n",
    "    df_topic = df_first_level[df_first_level['first_level_topic'] == topic].copy()\n",
    "    save_dict_path = \"./output/lda/dictionary1_\"+str(topic+1)+\".pickle\"\n",
    "    save_LDA_model_path = \"./output/lda/LDA_model1_\" + str(topic + 1)\n",
    "    \n",
    "    df_data_tmp = tm.prepare_for_modeling(data_path=\"\", model_type=\"LDA\",\n",
    "                                       params={\"TEXT_prepared_df\": df_topic,\n",
    "                                               \"save_LDA_dictionary_path\": save_dict_path\n",
    "                                               },\n",
    "                                       verbose=1)\n",
    "\n",
    "    df_2nd_tmp = tm.train_model(model_type=\"LDA\",\n",
    "                                params={\"num_topics\": num_topics_2,\n",
    "                                        \"LDA_prepared_df\": df_data_tmp,\n",
    "                                        \"LDA_dictionary_path\": save_dict_path,\n",
    "                                        \"save_LDA_model_path\": save_LDA_model_path\n",
    "                                        },\n",
    "                                verbose=1)\n",
    "\n",
    "    #value counts of SECOND level topics\n",
    "    print(\"\\nValue counts of SECOND level topics:\")\n",
    "    df_2nd_tmp['second_level_topic'] = df_2nd_tmp['top_topic']\n",
    "    df_2nd_tmp['second_level_topic_proba'] = df_2nd_tmp['top_topic_proba']\n",
    "    print(df_2nd_tmp['second_level_topic'].value_counts().sort_index())\n",
    "\n",
    "    print(\"#\"*50)\n",
    "    df_2nd_tmp = df_2nd_tmp.drop(columns=['selected_words', 'doc2bow',\n",
    "                                           'infered_topics', 'top_topic', 'top_topic_proba'])\n",
    "    list_dfs.append(df_2nd_tmp)\n",
    "finish = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of gettig Second level topics in minutes: 8.13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['date', 'author', 'title', 'url', 'section', 'publication',\n",
       "       'first_10_sents', 'list_of_first_10_sents', 'list_of_verb_lemmas',\n",
       "       'noun_phrases', 'list_of_nouns', 'list_of_lemmas', 'ID',\n",
       "       'group_level_1', 'group_level_2', 'group_level_3', 'first_level_topic',\n",
       "       'first_level_topic_proba', 'second_level_topic',\n",
       "       'second_level_topic_proba'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Time of gettig Second level topics in minutes:\", round((finish-start)/60,2))\n",
    "df_second_level = pd.concat(list_dfs)\n",
    "df_second_level.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Get THIRD level topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_level_topic</th>\n",
       "      <th>first_level_topic_proba</th>\n",
       "      <th>second_level_topic</th>\n",
       "      <th>second_level_topic_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33979.000000</td>\n",
       "      <td>33979.000000</td>\n",
       "      <td>33979.000000</td>\n",
       "      <td>33979.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.967863</td>\n",
       "      <td>0.678492</td>\n",
       "      <td>2.050855</td>\n",
       "      <td>0.739948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.773743</td>\n",
       "      <td>0.195395</td>\n",
       "      <td>1.403456</td>\n",
       "      <td>0.195570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.519647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.568842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.659102</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.733796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.849835</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.966375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.990098</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.991709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_level_topic  first_level_topic_proba  second_level_topic  \\\n",
       "count       33979.000000             33979.000000        33979.000000   \n",
       "mean            4.967863                 0.678492            2.050855   \n",
       "std             2.773743                 0.195395            1.403456   \n",
       "min             0.000000                 0.213854            0.000000   \n",
       "25%             3.000000                 0.519647            1.000000   \n",
       "50%             6.000000                 0.659102            2.000000   \n",
       "75%             7.000000                 0.849835            3.000000   \n",
       "max             9.000000                 0.990098            4.000000   \n",
       "\n",
       "       second_level_topic_proba  \n",
       "count              33979.000000  \n",
       "mean                   0.739948  \n",
       "std                    0.195570  \n",
       "min                    0.242436  \n",
       "25%                    0.568842  \n",
       "50%                    0.733796  \n",
       "75%                    0.966375  \n",
       "max                    0.991709  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_second_level[['first_level_topic',\n",
    "       'first_level_topic_proba', 'second_level_topic',\n",
    "       'second_level_topic_proba']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected FIRST level topic index: 0\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (0, 0)\n",
      "loaded data shape: (247, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_1_1\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    247\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (0, 1)\n",
      "loaded data shape: (319, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_1_2\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "1    319\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (0, 2)\n",
      "loaded data shape: (235, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_1_3\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "2    235\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (0, 3)\n",
      "loaded data shape: (297, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_1_4\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "3    297\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (0, 4)\n",
      "loaded data shape: (359, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_1_5\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "4    359\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 1\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (1, 0)\n",
      "loaded data shape: (743, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_2_1\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    743\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (1, 1)\n",
      "loaded data shape: (1391, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_2_2\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "1    1391\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (1, 2)\n",
      "loaded data shape: (742, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_2_3\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "2    742\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (1, 3)\n",
      "loaded data shape: (1078, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_2_4\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "3    1078\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (1, 4)\n",
      "loaded data shape: (1045, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_2_5\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "4    1045\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 2\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (2, 0)\n",
      "loaded data shape: (247, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_3_1\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    247\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (2, 1)\n",
      "loaded data shape: (469, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_3_2\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "1    469\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (2, 2)\n",
      "loaded data shape: (231, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_3_3\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "2    231\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (2, 3)\n",
      "loaded data shape: (480, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_3_4\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "3    480\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (2, 4)\n",
      "loaded data shape: (535, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_3_5\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "4    535\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 3\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (3, 0)\n",
      "loaded data shape: (560, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_4_1\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    560\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (3, 1)\n",
      "loaded data shape: (875, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_4_2\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "1    875\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (3, 2)\n",
      "loaded data shape: (619, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_4_3\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "2    619\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (3, 3)\n",
      "loaded data shape: (384, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_4_4\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "3    384\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (3, 4)\n",
      "loaded data shape: (695, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_4_5\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "4    695\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 4\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (4, 0)\n",
      "loaded data shape: (326, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_5_1\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    326\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (4, 1)\n",
      "loaded data shape: (391, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_5_2\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "1    391\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (4, 2)\n",
      "loaded data shape: (439, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_5_3\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "2    439\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (4, 3)\n",
      "loaded data shape: (531, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_5_4\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "3    531\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (4, 4)\n",
      "loaded data shape: (409, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_5_5\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "4    409\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 5\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (5, 0)\n",
      "loaded data shape: (784, 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_6_1\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    784\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (5, 1)\n",
      "loaded data shape: (479, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_6_2\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "1    479\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (5, 2)\n",
      "loaded data shape: (493, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_6_3\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "2    493\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (5, 3)\n",
      "loaded data shape: (609, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_6_4\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "3    609\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (5, 4)\n",
      "loaded data shape: (497, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_6_5\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "4    497\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 6\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (6, 0)\n",
      "loaded data shape: (654, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_7_1\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    654\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (6, 1)\n",
      "loaded data shape: (1090, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_7_2\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "1    1090\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (6, 2)\n",
      "loaded data shape: (635, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_7_3\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "2    635\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (6, 3)\n",
      "loaded data shape: (1129, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_7_4\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "3    1129\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (6, 4)\n",
      "loaded data shape: (837, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_7_5\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "4    837\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 7\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (7, 0)\n",
      "loaded data shape: (1458, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_8_1\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    1458\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (7, 1)\n",
      "loaded data shape: (1258, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_8_2\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "1    1258\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (7, 2)\n",
      "loaded data shape: (906, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_8_3\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "2    906\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (7, 3)\n",
      "loaded data shape: (1587, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_8_4\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "3    1587\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (7, 4)\n",
      "loaded data shape: (1424, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_8_5\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "4    1424\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 8\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (8, 0)\n",
      "loaded data shape: (606, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_9_1\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    606\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (8, 1)\n",
      "loaded data shape: (566, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_9_2\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "1    566\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (8, 2)\n",
      "loaded data shape: (818, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_9_3\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "2    818\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (8, 3)\n",
      "loaded data shape: (647, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_9_4\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "3    647\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (8, 4)\n",
      "loaded data shape: (505, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_9_5\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "4    505\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 9\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (9, 0)\n",
      "loaded data shape: (493, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_10_1\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    493\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (9, 1)\n",
      "loaded data shape: (592, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_10_2\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "1    592\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (9, 2)\n",
      "loaded data shape: (778, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_10_3\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "2    778\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (9, 3)\n",
      "loaded data shape: (934, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_10_4\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "3    934\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topics' indexes: (9, 4)\n",
      "loaded data shape: (553, 20)\n",
      "Training LDA with only lemmas of NOUNs, VERBs, ADJs and ADVs\n",
      "LDA model file is saved to: ./output/lda/LDA_model1_10_5\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "4    553\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "list_dfs = []\n",
    "\n",
    "for topic_1st in first_level_topics:\n",
    "    print(\"\\nSelected FIRST level topic index:\",topic_1st)\n",
    "    df_1st_tmp = df_second_level[df_second_level['first_level_topic'] == topic_1st].copy()\n",
    "    second_level_topics = list(set(df_1st_tmp['second_level_topic']))\n",
    "    print(\"second_level_topics\", second_level_topics)\n",
    "    \n",
    "    for topic_2nd in second_level_topics:\n",
    "        print(\"\\nSelected topics' indexes:\", (topic_1st, topic_2nd))\n",
    "        \n",
    "        save_dict_path = \"./output/lda/dictionary1_\"+str(topic_1st+1)+\"_\"+str(topic_2nd+1)+\".pickle\"\n",
    "        save_LDA_model_path = \"./output/lda/LDA_model1_\"+str(topic_1st+1)+\"_\"+str(topic_2nd+1)\n",
    "        \n",
    "        df_2nd_tmp = df_1st_tmp[df_1st_tmp['second_level_topic'] == topic_2nd].copy()\n",
    "        \n",
    "        df_data_tmp = tm.prepare_for_modeling(data_path=\"\", model_type=\"LDA\",\n",
    "                                           params={\"TEXT_prepared_df\": df_2nd_tmp,\n",
    "                                                   \"save_LDA_dictionary_path\": save_dict_path\n",
    "                                                   },\n",
    "                                           verbose=1)\n",
    "\n",
    "        df_3d_tmp = tm.train_model(model_type=\"LDA\",\n",
    "                                    params={\"num_topics\": num_topics_3,\n",
    "                                            \"LDA_prepared_df\": df_data_tmp,\n",
    "                                            \"LDA_dictionary_path\": save_dict_path,\n",
    "                                            \"save_LDA_model_path\": save_LDA_model_path,\n",
    "                                            },\n",
    "                                    verbose=1)\n",
    "\n",
    "        #value counts of SECOND level topics\n",
    "        print(\"\\nValue counts of SECOND level topics:\")\n",
    "        df_3d_tmp['third_level_topic'] = df_3d_tmp['top_topic']\n",
    "        df_3d_tmp['third_level_topic_proba'] = df_3d_tmp['top_topic_proba']\n",
    "        print(df_3d_tmp['second_level_topic'].value_counts().sort_index())\n",
    "\n",
    "        print(\"#\"*50)\n",
    "        df_3d_tmp = df_3d_tmp.drop(columns=['selected_words', 'doc2bow',\n",
    "                                               'infered_topics', 'top_topic', 'top_topic_proba'])\n",
    "        list_dfs.append(df_3d_tmp)\n",
    "finish = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of gettig Third level topics in minutes: 11.38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['date', 'author', 'title', 'url', 'section', 'publication',\n",
       "       'first_10_sents', 'list_of_first_10_sents', 'list_of_verb_lemmas',\n",
       "       'noun_phrases', 'list_of_nouns', 'list_of_lemmas', 'ID',\n",
       "       'group_level_1', 'group_level_2', 'group_level_3', 'first_level_topic',\n",
       "       'first_level_topic_proba', 'second_level_topic',\n",
       "       'second_level_topic_proba', 'third_level_topic',\n",
       "       'third_level_topic_proba'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Time of gettig Third level topics in minutes:\", round((finish-start)/60,2))\n",
    "df_third_level = pd.concat(list_dfs)\n",
    "df_third_level.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first_level_topic</th>\n",
       "      <td>33979.0</td>\n",
       "      <td>4.967863</td>\n",
       "      <td>2.773743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_level_topic_proba</th>\n",
       "      <td>33979.0</td>\n",
       "      <td>0.678492</td>\n",
       "      <td>0.195395</td>\n",
       "      <td>0.213854</td>\n",
       "      <td>0.519647</td>\n",
       "      <td>0.659102</td>\n",
       "      <td>0.849835</td>\n",
       "      <td>0.990098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_level_topic</th>\n",
       "      <td>33979.0</td>\n",
       "      <td>2.050855</td>\n",
       "      <td>1.403456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_level_topic_proba</th>\n",
       "      <td>33979.0</td>\n",
       "      <td>0.739948</td>\n",
       "      <td>0.195570</td>\n",
       "      <td>0.242436</td>\n",
       "      <td>0.568842</td>\n",
       "      <td>0.733796</td>\n",
       "      <td>0.966375</td>\n",
       "      <td>0.991709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_level_topic</th>\n",
       "      <td>33979.0</td>\n",
       "      <td>1.018953</td>\n",
       "      <td>0.813496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_level_topic_proba</th>\n",
       "      <td>33979.0</td>\n",
       "      <td>0.819664</td>\n",
       "      <td>0.181521</td>\n",
       "      <td>0.336766</td>\n",
       "      <td>0.655216</td>\n",
       "      <td>0.909433</td>\n",
       "      <td>0.980982</td>\n",
       "      <td>0.991845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            count      mean       std       min       25%  \\\n",
       "first_level_topic         33979.0  4.967863  2.773743  0.000000  3.000000   \n",
       "first_level_topic_proba   33979.0  0.678492  0.195395  0.213854  0.519647   \n",
       "second_level_topic        33979.0  2.050855  1.403456  0.000000  1.000000   \n",
       "second_level_topic_proba  33979.0  0.739948  0.195570  0.242436  0.568842   \n",
       "third_level_topic         33979.0  1.018953  0.813496  0.000000  0.000000   \n",
       "third_level_topic_proba   33979.0  0.819664  0.181521  0.336766  0.655216   \n",
       "\n",
       "                               50%       75%       max  \n",
       "first_level_topic         6.000000  7.000000  9.000000  \n",
       "first_level_topic_proba   0.659102  0.849835  0.990098  \n",
       "second_level_topic        2.000000  3.000000  4.000000  \n",
       "second_level_topic_proba  0.733796  0.966375  0.991709  \n",
       "third_level_topic         1.000000  2.000000  2.000000  \n",
       "third_level_topic_proba   0.909433  0.980982  0.991845  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = df_third_level.copy()\n",
    "df_result[['first_level_topic',\n",
    "       'first_level_topic_proba', 'second_level_topic',\n",
    "       'second_level_topic_proba', 'third_level_topic',\n",
    "       'third_level_topic_proba']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>second_level_topic</th>\n",
       "      <th>third_level_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24575</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20545</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11355</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23974</th>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      second_level_topic third_level_topic\n",
       "221                  0.0             0.0.1\n",
       "24575                0.3             0.3.1\n",
       "20545                1.0             1.0.0\n",
       "11355                1.1             1.1.0\n",
       "23974                1.2             1.2.1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['second_level_topic'] = df_result['first_level_topic'].apply(str) + \".\" +\\\n",
    "                                  df_result['second_level_topic'].apply(str)\n",
    "df_result['third_level_topic'] = df_result['second_level_topic'].apply(str) + \".\" +\\\n",
    "                                  df_result['third_level_topic'].apply(str)\n",
    "df_result[['second_level_topic','third_level_topic']].iloc[::1000].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of first level clusters per publication section:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>10%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>90%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first_level_topic</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.357143</td>\n",
       "      <td>3.387923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count      mean       std  min  10%   25%   50%   75%  \\\n",
       "first_level_topic   14.0  8.357143  3.387923  1.0  2.2  10.0  10.0  10.0   \n",
       "\n",
       "                    90%   max  \n",
       "first_level_topic  10.0  10.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of first level clusters per publication section:\")\n",
    "pd.DataFrame(df_result.groupby('section')['first_level_topic'].nunique().describe(percentiles=[0.1,\n",
    "                                                                                   0.25,0.5,0.75,0.9])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "health                   8237\n",
       "business                 6930\n",
       "culture                  3246\n",
       "science                  2910\n",
       "tech                     2527\n",
       "gear                     2108\n",
       "security                 1840\n",
       "transportation           1666\n",
       "finance-and-economics    1648\n",
       "Space                    1641\n",
       "Health                   1193\n",
       "movies                     31\n",
       "style                       1\n",
       "music                       1\n",
       "Name: section, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['section'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_level_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8237.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.748938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.110383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_level_topic\n",
       "count        8237.000000\n",
       "mean            4.748938\n",
       "std             2.110383\n",
       "min             0.000000\n",
       "10%             2.000000\n",
       "25%             4.000000\n",
       "50%             5.000000\n",
       "75%             6.000000\n",
       "90%             7.000000\n",
       "max             9.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test single section\n",
    "section = \"health\"\n",
    "df_result[df_result['section'] == section][['first_level_topic',\n",
    "                                            'second_level_topic',\n",
    "                                            'third_level_topic']].describe(percentiles=[0.1,\n",
    "                                                                                   0.25,0.5,0.75,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of first level clusters per 30% semantic similarity group:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>10%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>90%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first_level_topic</th>\n",
       "      <td>571.0</td>\n",
       "      <td>3.565674</td>\n",
       "      <td>2.878318</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count      mean       std  min  10%  25%  50%  75%  90%  \\\n",
       "first_level_topic  571.0  3.565674  2.878318  1.0  1.0  1.0  2.0  5.0  9.0   \n",
       "\n",
       "                    max  \n",
       "first_level_topic  10.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of first level clusters per 30% semantic similarity group:\")\n",
    "pd.DataFrame(df_result.groupby('group_level_1')['first_level_topic'].nunique().describe(percentiles=[0.1,\n",
    "                                                                                   0.25,0.5,0.75,0.9])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of second level clusters per 50% semantic similarity group:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>10%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>90%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>second_level_topic</th>\n",
       "      <td>6767.0</td>\n",
       "      <td>2.274716</td>\n",
       "      <td>2.984201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count      mean       std  min  10%  25%  50%  75%  90%  \\\n",
       "second_level_topic  6767.0  2.274716  2.984201  1.0  1.0  1.0  1.0  2.0  5.0   \n",
       "\n",
       "                     max  \n",
       "second_level_topic  41.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of second level clusters per 50% semantic similarity group:\")\n",
    "pd.DataFrame(df_result.groupby('group_level_2')['second_level_topic'].nunique().describe(percentiles=[0.1,\n",
    "                                                                                   0.25,0.5,0.75,0.9])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of third level clusters per 70% semantic similarity group:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>10%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>90%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>third_level_topic</th>\n",
       "      <td>22065.0</td>\n",
       "      <td>1.257738</td>\n",
       "      <td>0.921828</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count      mean       std  min  10%  25%  50%  75%  90%  \\\n",
       "third_level_topic  22065.0  1.257738  0.921828  1.0  1.0  1.0  1.0  1.0  2.0   \n",
       "\n",
       "                    max  \n",
       "third_level_topic  27.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of third level clusters per 70% semantic similarity group:\")\n",
    "pd.DataFrame(df_result.groupby('group_level_3')['third_level_topic'].nunique().describe(percentiles=[0.1,\n",
    "                                                                                   0.25,0.5,0.75,0.9])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/df_result.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(df_result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df_result\n",
    "with open('./output/df_result.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    df_result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>221</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>306</th>\n",
       "      <th>448</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>2016-04-09 00:00:00</td>\n",
       "      <td>2016-05-12 00:00:00</td>\n",
       "      <td>2016-05-12 00:00:00</td>\n",
       "      <td>2016-05-19 00:00:00</td>\n",
       "      <td>2016-07-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>Dumping and tub-thumping - Free exchange</td>\n",
       "      <td>Snappy dressers - Crocodile farming</td>\n",
       "      <td>Snuffed out - Tobacco firms</td>\n",
       "      <td>The leeward side of fortune - Pacific economies</td>\n",
       "      <td>Silicon Valley 1.0 - Schumpeter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>https://www.economist.com/finance-and-economic...</td>\n",
       "      <td>https://www.economist.com/business/2016/05/12/...</td>\n",
       "      <td>https://www.economist.com/business/2016/05/12/...</td>\n",
       "      <td>https://www.economist.com/finance-and-economic...</td>\n",
       "      <td>https://www.economist.com/business/2016/07/23/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section</th>\n",
       "      <td>finance-and-economics</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>finance-and-economics</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <td>Economist</td>\n",
       "      <td>Economist</td>\n",
       "      <td>Economist</td>\n",
       "      <td>Economist</td>\n",
       "      <td>Economist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_10_sents</th>\n",
       "      <td>IT WAS a flood of cheap steel from an intimida...</td>\n",
       "      <td>SOME 30,000 crocodiles bask at Izintaba, a far...</td>\n",
       "      <td>THE interests of cigarettemakers and regulator...</td>\n",
       "      <td>THE phrase Pacific island conjures images of w...</td>\n",
       "      <td>WHEN the Republican Party decided to hold its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>list_of_first_10_sents</th>\n",
       "      <td>['IT WAS a flood of cheap steel from an intimi...</td>\n",
       "      <td>['SOME 30,000 crocodiles bask at Izintaba, a f...</td>\n",
       "      <td>['THE interests of cigarettemakers and regulat...</td>\n",
       "      <td>['THE phrase Pacific island conjures images of...</td>\n",
       "      <td>['WHEN the Republican Party decided to hold it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>list_of_verb_lemmas</th>\n",
       "      <td>[intimidating, prompted, angered, soaring, imp...</td>\n",
       "      <td>[bask, sprawled, Sold, watch, fetch, requires,...</td>\n",
       "      <td>[align, came, announced, expanding, grew, acco...</td>\n",
       "      <td>[conjures, served, halved, run, contend, risin...</td>\n",
       "      <td>[decided, hold, dreamed, suited, think, illust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noun_phrases</th>\n",
       "      <td>['flood', 'cheap steel', 'intimidating new eco...</td>\n",
       "      <td>['Izintaba', 'farm', 'acre', 'South African ci...</td>\n",
       "      <td>['interest', 'cigarettemaker', 'regulator', 'd...</td>\n",
       "      <td>['phrase Pacific island conjures image', 'whit...</td>\n",
       "      <td>['Republican Party', 'national convention', 'C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>list_of_nouns</th>\n",
       "      <td>[flood, steel, power, passage, worlds, antidum...</td>\n",
       "      <td>[crocodiles, farm, acres, city, tanners, bags,...</td>\n",
       "      <td>[interests, cigarettemakers, regulators, date,...</td>\n",
       "      <td>[phrase, island, images, whitesand, beaches, t...</td>\n",
       "      <td>[convention, nominee, city, man, city, campaig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>list_of_lemmas</th>\n",
       "      <td>[flood, cheap, steel, intimidating, new, econo...</td>\n",
       "      <td>[crocodiles, bask, farm, sprawled, acres, sout...</td>\n",
       "      <td>[interests, cigarettemakers, regulators, rarel...</td>\n",
       "      <td>[phrase, island, conjures, images, whitesand, ...</td>\n",
       "      <td>[decided, hold, national, convention, dreamed,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>221</td>\n",
       "      <td>288</td>\n",
       "      <td>289</td>\n",
       "      <td>306</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_level_1</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_level_2</th>\n",
       "      <td>48</td>\n",
       "      <td>148</td>\n",
       "      <td>133</td>\n",
       "      <td>153</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_level_3</th>\n",
       "      <td>210</td>\n",
       "      <td>267</td>\n",
       "      <td>238</td>\n",
       "      <td>283</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_level_topic</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_level_topic_proba</th>\n",
       "      <td>0.496915</td>\n",
       "      <td>0.811497</td>\n",
       "      <td>0.962463</td>\n",
       "      <td>0.364123</td>\n",
       "      <td>0.342782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_level_topic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_level_topic_proba</th>\n",
       "      <td>0.628757</td>\n",
       "      <td>0.983775</td>\n",
       "      <td>0.727035</td>\n",
       "      <td>0.772572</td>\n",
       "      <td>0.981851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_level_topic</th>\n",
       "      <td>0.0.1</td>\n",
       "      <td>0.0.1</td>\n",
       "      <td>0.0.1</td>\n",
       "      <td>0.0.0</td>\n",
       "      <td>0.0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_level_topic_proba</th>\n",
       "      <td>0.984345</td>\n",
       "      <td>0.585893</td>\n",
       "      <td>0.903832</td>\n",
       "      <td>0.974390</td>\n",
       "      <td>0.972327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        221  \\\n",
       "date                                                    2016-04-09 00:00:00   \n",
       "author                                                                  NaN   \n",
       "title                              Dumping and tub-thumping - Free exchange   \n",
       "url                       https://www.economist.com/finance-and-economic...   \n",
       "section                                               finance-and-economics   \n",
       "publication                                                       Economist   \n",
       "first_10_sents            IT WAS a flood of cheap steel from an intimida...   \n",
       "list_of_first_10_sents    ['IT WAS a flood of cheap steel from an intimi...   \n",
       "list_of_verb_lemmas       [intimidating, prompted, angered, soaring, imp...   \n",
       "noun_phrases              ['flood', 'cheap steel', 'intimidating new eco...   \n",
       "list_of_nouns             [flood, steel, power, passage, worlds, antidum...   \n",
       "list_of_lemmas            [flood, cheap, steel, intimidating, new, econo...   \n",
       "ID                                                                      221   \n",
       "group_level_1                                                             1   \n",
       "group_level_2                                                            48   \n",
       "group_level_3                                                           210   \n",
       "first_level_topic                                                         0   \n",
       "first_level_topic_proba                                            0.496915   \n",
       "second_level_topic                                                      0.0   \n",
       "second_level_topic_proba                                           0.628757   \n",
       "third_level_topic                                                     0.0.1   \n",
       "third_level_topic_proba                                            0.984345   \n",
       "\n",
       "                                                                        288  \\\n",
       "date                                                    2016-05-12 00:00:00   \n",
       "author                                                                  NaN   \n",
       "title                                   Snappy dressers - Crocodile farming   \n",
       "url                       https://www.economist.com/business/2016/05/12/...   \n",
       "section                                                            business   \n",
       "publication                                                       Economist   \n",
       "first_10_sents            SOME 30,000 crocodiles bask at Izintaba, a far...   \n",
       "list_of_first_10_sents    ['SOME 30,000 crocodiles bask at Izintaba, a f...   \n",
       "list_of_verb_lemmas       [bask, sprawled, Sold, watch, fetch, requires,...   \n",
       "noun_phrases              ['Izintaba', 'farm', 'acre', 'South African ci...   \n",
       "list_of_nouns             [crocodiles, farm, acres, city, tanners, bags,...   \n",
       "list_of_lemmas            [crocodiles, bask, farm, sprawled, acres, sout...   \n",
       "ID                                                                      288   \n",
       "group_level_1                                                            24   \n",
       "group_level_2                                                           148   \n",
       "group_level_3                                                           267   \n",
       "first_level_topic                                                         0   \n",
       "first_level_topic_proba                                            0.811497   \n",
       "second_level_topic                                                      0.0   \n",
       "second_level_topic_proba                                           0.983775   \n",
       "third_level_topic                                                     0.0.1   \n",
       "third_level_topic_proba                                            0.585893   \n",
       "\n",
       "                                                                        289  \\\n",
       "date                                                    2016-05-12 00:00:00   \n",
       "author                                                                  NaN   \n",
       "title                                           Snuffed out - Tobacco firms   \n",
       "url                       https://www.economist.com/business/2016/05/12/...   \n",
       "section                                                            business   \n",
       "publication                                                       Economist   \n",
       "first_10_sents            THE interests of cigarettemakers and regulator...   \n",
       "list_of_first_10_sents    ['THE interests of cigarettemakers and regulat...   \n",
       "list_of_verb_lemmas       [align, came, announced, expanding, grew, acco...   \n",
       "noun_phrases              ['interest', 'cigarettemaker', 'regulator', 'd...   \n",
       "list_of_nouns             [interests, cigarettemakers, regulators, date,...   \n",
       "list_of_lemmas            [interests, cigarettemakers, regulators, rarel...   \n",
       "ID                                                                      289   \n",
       "group_level_1                                                             2   \n",
       "group_level_2                                                           133   \n",
       "group_level_3                                                           238   \n",
       "first_level_topic                                                         0   \n",
       "first_level_topic_proba                                            0.962463   \n",
       "second_level_topic                                                      0.0   \n",
       "second_level_topic_proba                                           0.727035   \n",
       "third_level_topic                                                     0.0.1   \n",
       "third_level_topic_proba                                            0.903832   \n",
       "\n",
       "                                                                        306  \\\n",
       "date                                                    2016-05-19 00:00:00   \n",
       "author                                                                  NaN   \n",
       "title                       The leeward side of fortune - Pacific economies   \n",
       "url                       https://www.economist.com/finance-and-economic...   \n",
       "section                                               finance-and-economics   \n",
       "publication                                                       Economist   \n",
       "first_10_sents            THE phrase Pacific island conjures images of w...   \n",
       "list_of_first_10_sents    ['THE phrase Pacific island conjures images of...   \n",
       "list_of_verb_lemmas       [conjures, served, halved, run, contend, risin...   \n",
       "noun_phrases              ['phrase Pacific island conjures image', 'whit...   \n",
       "list_of_nouns             [phrase, island, images, whitesand, beaches, t...   \n",
       "list_of_lemmas            [phrase, island, conjures, images, whitesand, ...   \n",
       "ID                                                                      306   \n",
       "group_level_1                                                            13   \n",
       "group_level_2                                                           153   \n",
       "group_level_3                                                           283   \n",
       "first_level_topic                                                         0   \n",
       "first_level_topic_proba                                            0.364123   \n",
       "second_level_topic                                                      0.0   \n",
       "second_level_topic_proba                                           0.772572   \n",
       "third_level_topic                                                     0.0.0   \n",
       "third_level_topic_proba                                            0.974390   \n",
       "\n",
       "                                                                        448  \n",
       "date                                                    2016-07-23 00:00:00  \n",
       "author                                                                  NaN  \n",
       "title                                       Silicon Valley 1.0 - Schumpeter  \n",
       "url                       https://www.economist.com/business/2016/07/23/...  \n",
       "section                                                            business  \n",
       "publication                                                       Economist  \n",
       "first_10_sents            WHEN the Republican Party decided to hold its ...  \n",
       "list_of_first_10_sents    ['WHEN the Republican Party decided to hold it...  \n",
       "list_of_verb_lemmas       [decided, hold, dreamed, suited, think, illust...  \n",
       "noun_phrases              ['Republican Party', 'national convention', 'C...  \n",
       "list_of_nouns             [convention, nominee, city, man, city, campaig...  \n",
       "list_of_lemmas            [decided, hold, national, convention, dreamed,...  \n",
       "ID                                                                      448  \n",
       "group_level_1                                                             1  \n",
       "group_level_2                                                            81  \n",
       "group_level_3                                                           400  \n",
       "first_level_topic                                                         0  \n",
       "first_level_topic_proba                                            0.342782  \n",
       "second_level_topic                                                      0.0  \n",
       "second_level_topic_proba                                           0.981851  \n",
       "third_level_topic                                                     0.0.1  \n",
       "third_level_topic_proba                                            0.972327  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Music      6633\n",
       "Hackers    4999\n",
       "Flu        4345\n",
       "Rocket     3350\n",
       "Fund       3142\n",
       "Videos     3133\n",
       "Drivers    2862\n",
       "Measles    2096\n",
       "Gun        1962\n",
       "Tobacco    1457\n",
       "Name: first_level_topic_name, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get first level topic names\n",
    "df = df_result.copy()\n",
    "\n",
    "LDA_model_path = \"./output/lda/LDA_model1\"\n",
    "num_topics = num_topics_1\n",
    "df['first_level_topic_name'] = tm.get_topic_names(df, 'first_level_topic', 'list_of_nouns',\n",
    "                                                 LDA_model_path, num_topics, num_words = 50)\n",
    "df['first_level_topic_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected FIRST level topic index: 0\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "Abortions     319\n",
      "Beer          247\n",
      "Chemicals     359\n",
      "Neutrality    297\n",
      "Recall        235\n",
      "Name: second_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 1\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "Ads                1078\n",
      "Documents          1045\n",
      "Exports             743\n",
      "Rates              1391\n",
      "Vulnerabilities     742\n",
      "Name: second_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 2\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "Coal           480\n",
      "Encryption     469\n",
      "Shootings      535\n",
      "Transgender    247\n",
      "Workers        231\n",
      "Name: second_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 3\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "Ads       875\n",
      "Board     560\n",
      "Deals     384\n",
      "Stores    619\n",
      "Union     695\n",
      "Name: second_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 4\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "Autism        391\n",
      "Depression    439\n",
      "Fentanyl      409\n",
      "Football      326\n",
      "Vaccines      531\n",
      "Name: second_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 5\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "Birth          479\n",
      "Jets           609\n",
      "Restaurants    497\n",
      "Students       784\n",
      "Transit        493\n",
      "Name: second_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 6\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "Flu       1129\n",
      "Gene       837\n",
      "Recall     635\n",
      "Sex       1090\n",
      "Sugar      654\n",
      "Name: second_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 7\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "Brain       1424\n",
      "Mph          906\n",
      "Speakers    1258\n",
      "Stores      1587\n",
      "Trailer     1458\n",
      "Name: second_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 8\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "Bitcoin    647\n",
      "Film       606\n",
      "Losses     818\n",
      "Rates      566\n",
      "Women      505\n",
      "Name: second_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 9\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "Capsule     778\n",
      "Comet       934\n",
      "Drone       493\n",
      "Galaxies    553\n",
      "Internet    592\n",
      "Name: second_level_topic_name, dtype: int64\n",
      "##################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['date', 'author', 'title', 'url', 'section', 'publication',\n",
       "       'first_10_sents', 'list_of_first_10_sents', 'list_of_verb_lemmas',\n",
       "       'noun_phrases', 'list_of_nouns', 'list_of_lemmas', 'ID',\n",
       "       'group_level_1', 'group_level_2', 'group_level_3', 'first_level_topic',\n",
       "       'first_level_topic_proba', 'second_level_topic',\n",
       "       'second_level_topic_proba', 'third_level_topic',\n",
       "       'third_level_topic_proba', 'first_level_topic_name',\n",
       "       'second_level_topic_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dfs = []\n",
    "for topic_1st in range(num_topics_1):\n",
    "    print(\"\\nSelected FIRST level topic index:\",topic_1st)\n",
    "    df_1st_tmp = df[df['first_level_topic'] == topic_1st].copy()\n",
    "    LDA_model_path = \"./output/lda/LDA_model1_\"+str(topic_1st+1)\n",
    "\n",
    "    df_1st_tmp['second_level_topic_name'] = tm.get_topic_names(df_1st_tmp, \n",
    "                                                                   'second_level_topic', \n",
    "                                                                   'list_of_nouns',\n",
    "                                                               LDA_model_path, num_topics_2, num_words = 50)\n",
    "\n",
    "    #value counts of SECOND level topics\n",
    "    print(\"\\nValue counts of SECOND level topics:\")\n",
    "    print(df_1st_tmp['second_level_topic_name'].value_counts().sort_index())\n",
    "    print(\"#\"*50)\n",
    "    list_dfs.append(df_1st_tmp)\n",
    "df_2_named = pd.concat(list_dfs)\n",
    "df_2_named.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected SECOND level topic index: 5.2\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Boys        145\n",
      "School      177\n",
      "Scooters    171\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 9.3\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Exoplanet    294\n",
      "Rings        303\n",
      "Rover        337\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 8.0\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Bankruptcy    176\n",
      "Brands        248\n",
      "Card          182\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 0.3\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Cannabis    132\n",
      "Lung         56\n",
      "Women       109\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 7.2\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Bike        321\n",
      "Children    278\n",
      "Episode     307\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 4.1\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Abuse             99\n",
      "Autism           173\n",
      "Prescriptions    119\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 9.4\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Evidence    213\n",
      "Images      131\n",
      "Wave        209\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 5.3\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Drone         226\n",
      "Pilots        179\n",
      "Production    204\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 6.0\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Coffee         205\n",
      "Meat           250\n",
      "Supplements    199\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 4.3\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Mumps     211\n",
      "School    122\n",
      "Trial     198\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 3.0\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Arrest        199\n",
      "Harassment    181\n",
      "State         180\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 9.1\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Fires        216\n",
      "Lightning    155\n",
      "Moon         221\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 3.2\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Grocery           220\n",
      "Misinformation    192\n",
      "Players           207\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 4.4\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Outbreak    141\n",
      "Study       157\n",
      "Trial       111\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 6.3\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Activity       364\n",
      "Antibiotics    438\n",
      "Mosquitoes     327\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 0.1\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Companies     86\n",
      "Death        130\n",
      "Tobacco      103\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 7.4\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Battery     501\n",
      "Blood       475\n",
      "Students    448\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 1.2\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Breach      179\n",
      "Election    288\n",
      "Sites       275\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 9.2\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Booster    264\n",
      "Rover      253\n",
      "Tag        261\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 5.4\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Breakfast    145\n",
      "Cases        188\n",
      "Wage         164\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 2.0\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Climate     78\n",
      "Identity    86\n",
      "Laws        83\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 3.4\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Children    260\n",
      "Contract    213\n",
      "Letter      222\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 0.4\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Agency      118\n",
      "Cannabis    126\n",
      "Plastic     115\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 1.4\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Equipment    394\n",
      "Health       325\n",
      "Numbers      326\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 8.2\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Managers    261\n",
      "Merger      291\n",
      "Stores      266\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 4.2\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Approval    120\n",
      "Dogs        227\n",
      "Pressure     92\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 6.2\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Lead        185\n",
      "Lettuce     216\n",
      "Listeria    234\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 6.1\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Alcohol      310\n",
      "Pregnancy    338\n",
      "Suicide      442\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 1.1\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Boss       470\n",
      "Gas        329\n",
      "Tariffs    592\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 5.1\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Cancer        161\n",
      "Rate           98\n",
      "Transplant    220\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 8.4\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "App         205\n",
      "Campaign    140\n",
      "Kidney      160\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 1.0\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Demand      233\n",
      "Networks    221\n",
      "Tariff      289\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 0.2\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Alternatives    109\n",
      "Code             83\n",
      "Fire             43\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 9.0\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Eruption    142\n",
      "Rocket      194\n",
      "Traffic     157\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 0.0\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Corn      75\n",
      "Laws      83\n",
      "Prices    89\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 8.3\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Bankruptcy      216\n",
      "Cash            205\n",
      "Transactions    226\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 2.2\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "School     86\n",
      "Water      56\n",
      "Workers    89\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 4.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts of THIRD level topics:\n",
      "Concussion    119\n",
      "Dementia       77\n",
      "Ear           130\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 1.3\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "App              281\n",
      "Campaigns        404\n",
      "Investigation    393\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 2.4\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Fiction    162\n",
      "Stores     158\n",
      "Student    215\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 7.3\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Console    524\n",
      "Network    473\n",
      "Stores     590\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 2.1\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Attack    142\n",
      "Gun       117\n",
      "Women     210\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 7.0\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Music     447\n",
      "Office    548\n",
      "Space     463\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 5.0\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Car        353\n",
      "Couples    207\n",
      "Death      224\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 6.4\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Heart         375\n",
      "Mosquitoes    239\n",
      "Water         223\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 8.1\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Climate      212\n",
      "Computers    124\n",
      "Yield        230\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 7.1\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Coffee    438\n",
      "Color     422\n",
      "Media     398\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 3.1\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Browser    375\n",
      "Bug        242\n",
      "Police     258\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 2.3\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Food     149\n",
      "Sea      197\n",
      "Smoke    134\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected SECOND level topic index: 3.3\n",
      "\n",
      "Value counts of THIRD level topics:\n",
      "Ads     118\n",
      "Jury    101\n",
      "Memo    165\n",
      "Name: third_level_topic_name, dtype: int64\n",
      "##################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['date', 'author', 'title', 'url', 'section', 'publication',\n",
       "       'first_10_sents', 'list_of_first_10_sents', 'list_of_verb_lemmas',\n",
       "       'noun_phrases', 'list_of_nouns', 'list_of_lemmas', 'ID',\n",
       "       'group_level_1', 'group_level_2', 'group_level_3', 'first_level_topic',\n",
       "       'first_level_topic_proba', 'second_level_topic',\n",
       "       'second_level_topic_proba', 'third_level_topic',\n",
       "       'third_level_topic_proba', 'first_level_topic_name',\n",
       "       'second_level_topic_name', 'third_level_topic_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dfs = []\n",
    "second_level_topics = list(set(df['second_level_topic']))\n",
    "for topic_2nd in second_level_topics:\n",
    "    print(\"\\nSelected SECOND level topic index:\",topic_2nd)\n",
    "    df_2nd_tmp = df_2_named[df_2_named['second_level_topic'] == topic_2nd].copy()\n",
    "    LDA_model_path = \"./output/lda/LDA_model1_\"+str(int(topic_2nd[0])+1)+\\\n",
    "                                                \"_\"+str(int(topic_2nd[-1])+1)\n",
    "\n",
    "    df_2nd_tmp['third_level_topic_name'] = tm.get_topic_names(df_2nd_tmp, \n",
    "                                                                   'third_level_topic', \n",
    "                                                                   'list_of_nouns',\n",
    "                                                               LDA_model_path, num_topics_3, num_words = 50)\n",
    "\n",
    "    #value counts of THIRD level topics\n",
    "    print(\"\\nValue counts of THIRD level topics:\")\n",
    "    print(df_2nd_tmp['third_level_topic_name'].value_counts().sort_index())\n",
    "    print(\"#\"*50)\n",
    "    list_dfs.append(df_2nd_tmp)\n",
    "df_3_named = pd.concat(list_dfs)\n",
    "df_3_named.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>278</th>\n",
       "      <th>14367</th>\n",
       "      <th>32118</th>\n",
       "      <th>25058</th>\n",
       "      <th>19153</th>\n",
       "      <th>7030</th>\n",
       "      <th>739</th>\n",
       "      <th>26492</th>\n",
       "      <th>10627</th>\n",
       "      <th>23541</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <td>Economist</td>\n",
       "      <td>Gizmodo</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Wired</td>\n",
       "      <td>Wired</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Economist</td>\n",
       "      <td>Wired</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Wired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section</th>\n",
       "      <td>finance-and-economics</td>\n",
       "      <td>Space</td>\n",
       "      <td>tech</td>\n",
       "      <td>transportation</td>\n",
       "      <td>culture</td>\n",
       "      <td>health</td>\n",
       "      <td>finance-and-economics</td>\n",
       "      <td>science</td>\n",
       "      <td>health</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_level_topic</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_level_topic_name</th>\n",
       "      <td>Drivers</td>\n",
       "      <td>Rocket</td>\n",
       "      <td>Fund</td>\n",
       "      <td>Music</td>\n",
       "      <td>Rocket</td>\n",
       "      <td>Flu</td>\n",
       "      <td>Videos</td>\n",
       "      <td>Rocket</td>\n",
       "      <td>Measles</td>\n",
       "      <td>Flu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_level_topic</th>\n",
       "      <td>5.2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_level_topic_name</th>\n",
       "      <td>Transit</td>\n",
       "      <td>Comet</td>\n",
       "      <td>Film</td>\n",
       "      <td>Mph</td>\n",
       "      <td>Galaxies</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Board</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Fentanyl</td>\n",
       "      <td>Flu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_level_topic</th>\n",
       "      <td>5.2.2</td>\n",
       "      <td>9.3.1</td>\n",
       "      <td>8.0.0</td>\n",
       "      <td>7.2.0</td>\n",
       "      <td>9.4.0</td>\n",
       "      <td>6.0.0</td>\n",
       "      <td>3.0.2</td>\n",
       "      <td>9.1.0</td>\n",
       "      <td>4.4.1</td>\n",
       "      <td>6.3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_level_topic_name</th>\n",
       "      <td>Scooters</td>\n",
       "      <td>Rings</td>\n",
       "      <td>Brands</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Wave</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Harassment</td>\n",
       "      <td>Fires</td>\n",
       "      <td>Study</td>\n",
       "      <td>Mosquitoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         278      14367   32118  \\\n",
       "publication                          Economist  Gizmodo     CNN   \n",
       "section                  finance-and-economics    Space    tech   \n",
       "first_level_topic                            5        9       8   \n",
       "first_level_topic_name                 Drivers   Rocket    Fund   \n",
       "second_level_topic                         5.2      9.3     8.0   \n",
       "second_level_topic_name                Transit    Comet    Film   \n",
       "third_level_topic                        5.2.2    9.3.1   8.0.0   \n",
       "third_level_topic_name                Scooters    Rings  Brands   \n",
       "\n",
       "                                  25058     19153   7030   \\\n",
       "publication                       Wired     Wired     CNN   \n",
       "section                  transportation   culture  health   \n",
       "first_level_topic                     7         9       6   \n",
       "first_level_topic_name            Music    Rocket     Flu   \n",
       "second_level_topic                  7.2       9.4     6.0   \n",
       "second_level_topic_name             Mph  Galaxies   Sugar   \n",
       "third_level_topic                 7.2.0     9.4.0   6.0.0   \n",
       "third_level_topic_name          Episode      Wave    Meat   \n",
       "\n",
       "                                         739       26492     10627       23541  \n",
       "publication                          Economist     Wired       CNN       Wired  \n",
       "section                  finance-and-economics   science    health     science  \n",
       "first_level_topic                            3         9         4           6  \n",
       "first_level_topic_name                  Videos    Rocket   Measles         Flu  \n",
       "second_level_topic                         3.0       9.1       4.4         6.3  \n",
       "second_level_topic_name                  Board  Internet  Fentanyl         Flu  \n",
       "third_level_topic                        3.0.2     9.1.0     4.4.1       6.3.0  \n",
       "third_level_topic_name              Harassment     Fires     Study  Mosquitoes  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_named[['publication', \n",
    "    'section',\n",
    "    'first_level_topic','first_level_topic_name',\n",
    "    'second_level_topic','second_level_topic_name',\n",
    "    'third_level_topic', 'third_level_topic_name'\n",
    "   ]].iloc[::1000].head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>30</th>\n",
       "      <th>328</th>\n",
       "      <th>496</th>\n",
       "      <th>159</th>\n",
       "      <th>1820</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first_level_topic</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_level_topic_name</th>\n",
       "      <td>Drivers</td>\n",
       "      <td>Drivers</td>\n",
       "      <td>Drivers</td>\n",
       "      <td>Gun</td>\n",
       "      <td>Gun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_level_topic</th>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_level_topic_name</th>\n",
       "      <td>Jets</td>\n",
       "      <td>Jets</td>\n",
       "      <td>Jets</td>\n",
       "      <td>Transgender</td>\n",
       "      <td>Transgender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_level_topic</th>\n",
       "      <td>5.3.2</td>\n",
       "      <td>5.3.1</td>\n",
       "      <td>5.3.0</td>\n",
       "      <td>2.0.2</td>\n",
       "      <td>2.0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_level_topic_name</th>\n",
       "      <td>Production</td>\n",
       "      <td>Pilots</td>\n",
       "      <td>Drone</td>\n",
       "      <td>Laws</td>\n",
       "      <td>Identity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               30       328      496          159   \\\n",
       "first_level_topic                 5        5        5            2   \n",
       "first_level_topic_name      Drivers  Drivers  Drivers          Gun   \n",
       "second_level_topic              5.3      5.3      5.3          2.0   \n",
       "second_level_topic_name        Jets     Jets     Jets  Transgender   \n",
       "third_level_topic             5.3.2    5.3.1    5.3.0        2.0.2   \n",
       "third_level_topic_name   Production   Pilots    Drone         Laws   \n",
       "\n",
       "                                1820  \n",
       "first_level_topic                  2  \n",
       "first_level_topic_name           Gun  \n",
       "second_level_topic               2.0  \n",
       "second_level_topic_name  Transgender  \n",
       "third_level_topic              2.0.1  \n",
       "third_level_topic_name      Identity  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics = df_3_named[[\n",
    "    'first_level_topic','first_level_topic_name',\n",
    "    'second_level_topic','second_level_topic_name',\n",
    "    'third_level_topic', 'third_level_topic_name'\n",
    "   ]].copy()\n",
    "df_topics = df_topics.drop_duplicates()\n",
    "print(df_topics.shape)\n",
    "df_topics.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/lda/topics.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(df_topics, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process unseen text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MOST people like to eat meat. As they grow richer they eat more of it. For individuals, that is good. Meat is nutritious. In particular, it packs much more protein per kilogram than plants do. But animals have to eat plants to put on weightso much so that feeding livestock accounts for about a third of harvested grain. Farm animals consume 8 of the worlds water supply, too. And they produce around 15 of unnatural greenhousegas emissions. More farm animals, then, could mean more environmental trouble. Some consumers, particularly in the rich West, get this.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 10\n",
    "\n",
    "text = df['first_10_sents'].iloc[ind]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_level_topic': 0,\n",
       " 'first_level_topic_name': 'Tobacco',\n",
       " 'first_level_topic_proba': 0.48858285,\n",
       " 'second_level_topic': 0,\n",
       " 'second_level_topic_name': 'Beer',\n",
       " 'second_level_topic_proba': 0.6123519,\n",
       " 'third_level_topic': 0,\n",
       " 'third_level_topic_name': 'Corn',\n",
       " 'third_level_topic_proba': 0.9637301}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.predict_topics(text,\n",
    "                  params={\"topics_df_path\": './output/lda/topics.pickle',\n",
    "                          \"first_dictionary_path\": \"./output/lda/dictionary1.pickle\" ,\n",
    "                          \"first_LDA_model_path\": \"./output/lda/LDA_model1\"\n",
    "                         }\n",
    "              )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
