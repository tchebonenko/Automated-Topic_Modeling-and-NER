{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea:\n",
    "Our solution: LDA + keywords from clusters of BERT based embeddings of noun phrases and verbs :\n",
    "- Each noun phrase and verb in the texts is  transformed to embedding vector using Universal Sentence Encoder (transformer based on BERT)\n",
    "- Embedding vectors from (a) are grouped into clusters with cosign similarity >= 70%\n",
    "- Words/phrases with embedding vectors closest to the centers of resulting clusters form key word/phrase\n",
    "- Each text in the training sample is converted to collection of key-phrases by replacing its noun phrases and verbs with keyword/phrases and deleting other words\n",
    "- LDA is performed on the transformed texts\n",
    "\n",
    "\n",
    "**Reference:**<br>\n",
    "- Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Constant, Mario Guajardo-CÃ©spedes, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil. **Universal Sentence Encoder.** *arXiv:1803.11175, 2018.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clNUUp3MUO2t"
   },
   "source": [
    "# Load data and python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1622131163361,
     "user": {
      "displayName": "Tatiana Chebonenko",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgwGu7u_TizJ74HmaMD0AtIfiksMdhRYrfZtevXzQ=s64",
      "userId": "10264586744881678851"
     },
     "user_tz": 240
    },
    "id": "7dYQIbH6UO2u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.2.0\n",
      "module https://tfhub.dev/google/universal-sentence-encoder-large/5 loaded\n"
     ]
    }
   ],
   "source": [
    "# data processing libraries\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# display wider columns in pandas data frames where necessary\n",
    "pd.set_option('max_colwidth',150)\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "#Load the Universal Sentence Encoder's TF Hub module\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape: (33982, 16)\n",
      "df_train.shape: Index(['date', 'author', 'title', 'url', 'section', 'publication',\n",
      "       'first_10_sents', 'list_of_first_10_sents', 'list_of_verb_lemmas',\n",
      "       'noun_phrases', 'list_of_nouns', 'list_of_lemmas', 'ID',\n",
      "       'group_level_1', 'group_level_2', 'group_level_3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./data/train_grouped.tsv\", sep=\"\\t\")\n",
    "print(\"df_train.shape:\", df_train.shape)\n",
    "print(\"df_train.shape:\",df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Bxk10XYUqNp"
   },
   "source": [
    "# Getting text clusters through sentence embedding comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1622131190534,
     "user": {
      "displayName": "Tatiana Chebonenko",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgwGu7u_TizJ74HmaMD0AtIfiksMdhRYrfZtevXzQ=s64",
      "userId": "10264586744881678851"
     },
     "user_tz": 240
    },
    "id": "MsgF9abaX2Bn"
   },
   "outputs": [],
   "source": [
    "def get_embeddings(input):\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embeddings(df_data, column = \"word\", N_batches=1):\n",
    "    #split data into N batches\n",
    "    N = N_batches\n",
    "\n",
    "    part = int(len(df_data)/N)\n",
    "    print(N, \"batches with\", part + 1, column + \"s each\")\n",
    "\n",
    "    #get embeddings for each N words\n",
    "    index = 0\n",
    "    batch_num = 0\n",
    "    list_dfs = []\n",
    "\n",
    "    while index < len(df_data): \n",
    "        df_tmp = df_data.iloc[index : index + part].copy()\n",
    "        df_tmp = df_tmp.reset_index(drop=True)\n",
    "        print (\"Batch number:\", batch_num + 1, \"out of \", N, \"index:\", index)\n",
    "\n",
    "        df_batch_embeddings = pd.DataFrame(get_embeddings(list(df_tmp[column])).numpy())\n",
    "\n",
    "        num_embeddings = df_batch_embeddings.shape[1]\n",
    "        columns = [\"emb_\" + str(i) for i in range(512)]\n",
    "        df_tmp[columns] = df_batch_embeddings\n",
    "\n",
    "        list_dfs.append(df_tmp)\n",
    "        batch_num = batch_num + 1\n",
    "        index = index + part\n",
    "\n",
    "    #concatinate batches into single dataset\n",
    "    df_emb = pd.concat(list_dfs)\n",
    "\n",
    "    return df_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [rise, big emerging economy, china, india, steady march, globalisation, surge, number, people, business, tourism, result, demand, visa, unpreceden...\n",
       "1    [pfizer, commitment, corporate social responsibility csr, drugs giant talk, responsibility, society, world, access, product, work, ngos, global he...\n",
       "2    [week, federal reserve, interest rate, time, year, world, central bank, rate, recent year, long spell, course, chart, outcome, americas rate rise,...\n",
       "3    [cruise line, wave, year, nearly, holiday, sea, result, december 18th carnival, worlds largest operator, global market, fullyear earning, demand, ...\n",
       "4    [investors, calendar year, buoyant mood, unexpected event, consensus, respect, view, investor, market price, column, potential surprise, definitio...\n",
       "Name: noun_phrases, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['noun_phrases'] = df_train['noun_phrases'].str[2:-2]\n",
    "df_train['noun_phrases'] = df_train['noun_phrases'].str.lower().str.split(\"', '\")\n",
    "df_train['noun_phrases'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['rise', 'big emerging economy', 'china', 'india', 'steady march'], 1417049)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_NPs = list(df_train['noun_phrases'])\n",
    "all_NPs = [np for l in all_NPs for np in l if len(np)>0]\n",
    "all_NPs[:5], len(all_NPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[emerging, led, wanting, travel, granted, Upgrade, travel, apply, submit, streamline, scrap]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['list_of_verb_lemmas'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                               [merging, led, wanting, travel, granted, upgrade, travel, apply, submit, streamline, scra]\n",
       "1    [rided, embracing, insists, gain, strengthen, improve, deterred, seeking, intends, shift, domiciled, rejoiced, saved, paid, outraged, promised, im...\n",
       "2    [aised, ended, celebrate, tried, lift, forced, reverse, cut, help, understand, upgrade, strike, wish, save, spend, try, escape, slashing, encourag...\n",
       "3      [race, booked, improve, announced, control, demand, peaking, piling, based, got, moving, upgrade, increase, announced, establish, aimed, based, ad]\n",
       "4    [tart, caught, proved, reflected, like, suggest, judged, betting, expect, upgrade, weakens, having, pushed, tighten, buy, priced, doubt, tighten, ...\n",
       "Name: list_of_verb_lemmas, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['list_of_verb_lemmas'] = df_train['list_of_verb_lemmas'].str[2:-2]\n",
    "df_train['list_of_verb_lemmas'] = df_train['list_of_verb_lemmas'].str.lower().str.split(\", \")\n",
    "df_train['list_of_verb_lemmas'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['merging', 'led', 'wanting', 'travel', 'granted'], 675330)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_Vs = list(df_train['list_of_verb_lemmas'])\n",
    "all_Vs = [v for l in all_Vs for v in l if len(v)>0]\n",
    "all_Vs[:5], len(all_Vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419327"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words =  list(set(all_NPs + all_Vs))\n",
    "len(set(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_QElB-4UM2z",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trusted trading partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>german sociologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>largest movie theater chain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emergency condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>right cameraa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          word\n",
       "0      trusted trading partner\n",
       "1           german sociologist\n",
       "2  largest movie theater chain\n",
       "3          emergency condition\n",
       "4                right cameraa"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words = pd.DataFrame({'word': all_words})\n",
    "df_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 batches with 4194 words each\n",
      "Batch number: 1 out of  100 index: 0\n",
      "Batch number: 2 out of  100 index: 4193\n",
      "Batch number: 3 out of  100 index: 8386\n",
      "Batch number: 4 out of  100 index: 12579\n",
      "Batch number: 5 out of  100 index: 16772\n",
      "Batch number: 6 out of  100 index: 20965\n",
      "Batch number: 7 out of  100 index: 25158\n",
      "Batch number: 8 out of  100 index: 29351\n",
      "Batch number: 9 out of  100 index: 33544\n",
      "Batch number: 10 out of  100 index: 37737\n",
      "Batch number: 11 out of  100 index: 41930\n",
      "Batch number: 12 out of  100 index: 46123\n",
      "Batch number: 13 out of  100 index: 50316\n",
      "Batch number: 14 out of  100 index: 54509\n",
      "Batch number: 15 out of  100 index: 58702\n",
      "Batch number: 16 out of  100 index: 62895\n",
      "Batch number: 17 out of  100 index: 67088\n",
      "Batch number: 18 out of  100 index: 71281\n",
      "Batch number: 19 out of  100 index: 75474\n",
      "Batch number: 20 out of  100 index: 79667\n",
      "Batch number: 21 out of  100 index: 83860\n",
      "Batch number: 22 out of  100 index: 88053\n",
      "Batch number: 23 out of  100 index: 92246\n",
      "Batch number: 24 out of  100 index: 96439\n",
      "Batch number: 25 out of  100 index: 100632\n",
      "Batch number: 26 out of  100 index: 104825\n",
      "Batch number: 27 out of  100 index: 109018\n",
      "Batch number: 28 out of  100 index: 113211\n",
      "Batch number: 29 out of  100 index: 117404\n",
      "Batch number: 30 out of  100 index: 121597\n",
      "Batch number: 31 out of  100 index: 125790\n",
      "Batch number: 32 out of  100 index: 129983\n",
      "Batch number: 33 out of  100 index: 134176\n",
      "Batch number: 34 out of  100 index: 138369\n",
      "Batch number: 35 out of  100 index: 142562\n",
      "Batch number: 36 out of  100 index: 146755\n",
      "Batch number: 37 out of  100 index: 150948\n",
      "Batch number: 38 out of  100 index: 155141\n",
      "Batch number: 39 out of  100 index: 159334\n",
      "Batch number: 40 out of  100 index: 163527\n",
      "Batch number: 41 out of  100 index: 167720\n",
      "Batch number: 42 out of  100 index: 171913\n",
      "Batch number: 43 out of  100 index: 176106\n",
      "Batch number: 44 out of  100 index: 180299\n",
      "Batch number: 45 out of  100 index: 184492\n",
      "Batch number: 46 out of  100 index: 188685\n",
      "Batch number: 47 out of  100 index: 192878\n",
      "Batch number: 48 out of  100 index: 197071\n",
      "Batch number: 49 out of  100 index: 201264\n",
      "Batch number: 50 out of  100 index: 205457\n",
      "Batch number: 51 out of  100 index: 209650\n",
      "Batch number: 52 out of  100 index: 213843\n",
      "Batch number: 53 out of  100 index: 218036\n",
      "Batch number: 54 out of  100 index: 222229\n",
      "Batch number: 55 out of  100 index: 226422\n",
      "Batch number: 56 out of  100 index: 230615\n",
      "Batch number: 57 out of  100 index: 234808\n",
      "Batch number: 58 out of  100 index: 239001\n",
      "Batch number: 59 out of  100 index: 243194\n",
      "Batch number: 60 out of  100 index: 247387\n",
      "Batch number: 61 out of  100 index: 251580\n",
      "Batch number: 62 out of  100 index: 255773\n",
      "Batch number: 63 out of  100 index: 259966\n",
      "Batch number: 64 out of  100 index: 264159\n",
      "Batch number: 65 out of  100 index: 268352\n",
      "Batch number: 66 out of  100 index: 272545\n",
      "Batch number: 67 out of  100 index: 276738\n",
      "Batch number: 68 out of  100 index: 280931\n",
      "Batch number: 69 out of  100 index: 285124\n",
      "Batch number: 70 out of  100 index: 289317\n",
      "Batch number: 71 out of  100 index: 293510\n",
      "Batch number: 72 out of  100 index: 297703\n",
      "Batch number: 73 out of  100 index: 301896\n",
      "Batch number: 74 out of  100 index: 306089\n",
      "Batch number: 75 out of  100 index: 310282\n",
      "Batch number: 76 out of  100 index: 314475\n",
      "Batch number: 77 out of  100 index: 318668\n",
      "Batch number: 78 out of  100 index: 322861\n",
      "Batch number: 79 out of  100 index: 327054\n",
      "Batch number: 80 out of  100 index: 331247\n",
      "Batch number: 81 out of  100 index: 335440\n",
      "Batch number: 82 out of  100 index: 339633\n",
      "Batch number: 83 out of  100 index: 343826\n",
      "Batch number: 84 out of  100 index: 348019\n",
      "Batch number: 85 out of  100 index: 352212\n",
      "Batch number: 86 out of  100 index: 356405\n",
      "Batch number: 87 out of  100 index: 360598\n",
      "Batch number: 88 out of  100 index: 364791\n",
      "Batch number: 89 out of  100 index: 368984\n",
      "Batch number: 90 out of  100 index: 373177\n",
      "Batch number: 91 out of  100 index: 377370\n",
      "Batch number: 92 out of  100 index: 381563\n",
      "Batch number: 93 out of  100 index: 385756\n",
      "Batch number: 94 out of  100 index: 389949\n",
      "Batch number: 95 out of  100 index: 394142\n",
      "Batch number: 96 out of  100 index: 398335\n",
      "Batch number: 97 out of  100 index: 402528\n",
      "Batch number: 98 out of  100 index: 406721\n",
      "Batch number: 99 out of  100 index: 410914\n",
      "Batch number: 100 out of  100 index: 415107\n",
      "Batch number: 101 out of  100 index: 419300\n",
      "CPU times: user 49min 40s, sys: 2min 14s, total: 51min 54s\n",
      "Wall time: 5min 15s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_502</th>\n",
       "      <th>emb_503</th>\n",
       "      <th>emb_504</th>\n",
       "      <th>emb_505</th>\n",
       "      <th>emb_506</th>\n",
       "      <th>emb_507</th>\n",
       "      <th>emb_508</th>\n",
       "      <th>emb_509</th>\n",
       "      <th>emb_510</th>\n",
       "      <th>emb_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>understated eyecatching design</td>\n",
       "      <td>-0.019827</td>\n",
       "      <td>-0.006422</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>-0.039300</td>\n",
       "      <td>-0.024002</td>\n",
       "      <td>0.054702</td>\n",
       "      <td>0.004713</td>\n",
       "      <td>-0.029246</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070869</td>\n",
       "      <td>-0.036970</td>\n",
       "      <td>-0.019612</td>\n",
       "      <td>-0.023454</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.076762</td>\n",
       "      <td>-0.026164</td>\n",
       "      <td>0.079127</td>\n",
       "      <td>-0.016291</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proinflammatory diet</td>\n",
       "      <td>0.047472</td>\n",
       "      <td>-0.036095</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>-0.057485</td>\n",
       "      <td>-0.034209</td>\n",
       "      <td>0.014092</td>\n",
       "      <td>-0.045369</td>\n",
       "      <td>-0.006103</td>\n",
       "      <td>0.041479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018932</td>\n",
       "      <td>-0.031069</td>\n",
       "      <td>-0.012415</td>\n",
       "      <td>0.022317</td>\n",
       "      <td>-0.053924</td>\n",
       "      <td>0.067012</td>\n",
       "      <td>-0.021760</td>\n",
       "      <td>0.060036</td>\n",
       "      <td>-0.045503</td>\n",
       "      <td>0.067614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peoples pocket</td>\n",
       "      <td>-0.077422</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.026393</td>\n",
       "      <td>-0.011804</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>-0.002622</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.075260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>-0.077545</td>\n",
       "      <td>0.012053</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>0.016847</td>\n",
       "      <td>0.053931</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.054155</td>\n",
       "      <td>-0.033633</td>\n",
       "      <td>0.000742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wacos bsr cable park</td>\n",
       "      <td>-0.028665</td>\n",
       "      <td>0.033037</td>\n",
       "      <td>-0.008898</td>\n",
       "      <td>0.025610</td>\n",
       "      <td>-0.021672</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>-0.074617</td>\n",
       "      <td>-0.022317</td>\n",
       "      <td>-0.077283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057017</td>\n",
       "      <td>-0.001560</td>\n",
       "      <td>0.057492</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.024517</td>\n",
       "      <td>0.086742</td>\n",
       "      <td>0.026507</td>\n",
       "      <td>-0.024543</td>\n",
       "      <td>0.035418</td>\n",
       "      <td>0.036425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andrea josse</td>\n",
       "      <td>-0.030393</td>\n",
       "      <td>0.026402</td>\n",
       "      <td>0.040522</td>\n",
       "      <td>-0.055174</td>\n",
       "      <td>0.037810</td>\n",
       "      <td>-0.047927</td>\n",
       "      <td>0.042512</td>\n",
       "      <td>-0.012625</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009257</td>\n",
       "      <td>0.040241</td>\n",
       "      <td>-0.040541</td>\n",
       "      <td>0.007010</td>\n",
       "      <td>0.017564</td>\n",
       "      <td>-0.009971</td>\n",
       "      <td>-0.039097</td>\n",
       "      <td>0.013524</td>\n",
       "      <td>0.041107</td>\n",
       "      <td>0.057602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             word     emb_0     emb_1     emb_2     emb_3  \\\n",
       "0  understated eyecatching design -0.019827 -0.006422  0.014570 -0.039300   \n",
       "1            proinflammatory diet  0.047472 -0.036095  0.003528 -0.057485   \n",
       "2                  peoples pocket -0.077422  0.006368  0.007027  0.026393   \n",
       "3            wacos bsr cable park -0.028665  0.033037 -0.008898  0.025610   \n",
       "4                    andrea josse -0.030393  0.026402  0.040522 -0.055174   \n",
       "\n",
       "      emb_4     emb_5     emb_6     emb_7     emb_8  ...   emb_502   emb_503  \\\n",
       "0 -0.024002  0.054702  0.004713 -0.029246  0.004955  ...  0.070869 -0.036970   \n",
       "1 -0.034209  0.014092 -0.045369 -0.006103  0.041479  ...  0.018932 -0.031069   \n",
       "2 -0.011804  0.010887 -0.002622  0.091837  0.075260  ...  0.017116 -0.077545   \n",
       "3 -0.021672  0.002751 -0.074617 -0.022317 -0.077283  ... -0.057017 -0.001560   \n",
       "4  0.037810 -0.047927  0.042512 -0.012625  0.005063  ... -0.009257  0.040241   \n",
       "\n",
       "    emb_504   emb_505   emb_506   emb_507   emb_508   emb_509   emb_510  \\\n",
       "0 -0.019612 -0.023454  0.000452 -0.076762 -0.026164  0.079127 -0.016291   \n",
       "1 -0.012415  0.022317 -0.053924  0.067012 -0.021760  0.060036 -0.045503   \n",
       "2  0.012053 -0.000137  0.016847  0.053931  0.004807  0.054155 -0.033633   \n",
       "3  0.057492  0.008258  0.024517  0.086742  0.026507 -0.024543  0.035418   \n",
       "4 -0.040541  0.007010  0.017564 -0.009971 -0.039097  0.013524  0.041107   \n",
       "\n",
       "    emb_511  \n",
       "0  0.000221  \n",
       "1  0.067614  \n",
       "2  0.000742  \n",
       "3  0.036425  \n",
       "4  0.057602  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#creating word2vec matrix\n",
    "df_w2v = get_word_embeddings(df_words, column = \"word\", N_batches=100)\n",
    "df_w2v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419327, 513)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_502</th>\n",
       "      <th>emb_503</th>\n",
       "      <th>emb_504</th>\n",
       "      <th>emb_505</th>\n",
       "      <th>emb_506</th>\n",
       "      <th>emb_507</th>\n",
       "      <th>emb_508</th>\n",
       "      <th>emb_509</th>\n",
       "      <th>emb_510</th>\n",
       "      <th>emb_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>understated eyecatching design</td>\n",
       "      <td>-0.019827</td>\n",
       "      <td>-0.006422</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>-0.039300</td>\n",
       "      <td>-0.024002</td>\n",
       "      <td>0.054702</td>\n",
       "      <td>0.004713</td>\n",
       "      <td>-0.029246</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070869</td>\n",
       "      <td>-0.036970</td>\n",
       "      <td>-0.019612</td>\n",
       "      <td>-0.023454</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.076762</td>\n",
       "      <td>-0.026164</td>\n",
       "      <td>0.079127</td>\n",
       "      <td>-0.016291</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3561</th>\n",
       "      <td>usual gear</td>\n",
       "      <td>0.030396</td>\n",
       "      <td>0.048733</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.030050</td>\n",
       "      <td>0.014397</td>\n",
       "      <td>-0.028559</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.052073</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043511</td>\n",
       "      <td>0.063861</td>\n",
       "      <td>-0.002875</td>\n",
       "      <td>0.009074</td>\n",
       "      <td>0.020639</td>\n",
       "      <td>-0.019907</td>\n",
       "      <td>-0.046328</td>\n",
       "      <td>0.063082</td>\n",
       "      <td>0.022643</td>\n",
       "      <td>0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>banco popular</td>\n",
       "      <td>-0.006136</td>\n",
       "      <td>0.053859</td>\n",
       "      <td>-0.027051</td>\n",
       "      <td>0.028665</td>\n",
       "      <td>0.007711</td>\n",
       "      <td>0.084763</td>\n",
       "      <td>-0.041701</td>\n",
       "      <td>-0.051199</td>\n",
       "      <td>-0.015713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.015526</td>\n",
       "      <td>0.015577</td>\n",
       "      <td>-0.044722</td>\n",
       "      <td>-0.044955</td>\n",
       "      <td>0.021150</td>\n",
       "      <td>-0.029704</td>\n",
       "      <td>-0.033842</td>\n",
       "      <td>-0.046479</td>\n",
       "      <td>0.021843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>trekkies</td>\n",
       "      <td>-0.027514</td>\n",
       "      <td>0.053677</td>\n",
       "      <td>0.028022</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>0.069076</td>\n",
       "      <td>-0.055233</td>\n",
       "      <td>0.026868</td>\n",
       "      <td>-0.025693</td>\n",
       "      <td>0.007560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037944</td>\n",
       "      <td>0.019393</td>\n",
       "      <td>-0.008219</td>\n",
       "      <td>-0.013544</td>\n",
       "      <td>-0.010799</td>\n",
       "      <td>0.046405</td>\n",
       "      <td>-0.019860</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>-0.011341</td>\n",
       "      <td>-0.003216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>harvard universitys t.h. chan school</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.031570</td>\n",
       "      <td>-0.016233</td>\n",
       "      <td>-0.085584</td>\n",
       "      <td>-0.027504</td>\n",
       "      <td>0.023182</td>\n",
       "      <td>-0.050383</td>\n",
       "      <td>-0.115471</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034805</td>\n",
       "      <td>-0.001658</td>\n",
       "      <td>0.077751</td>\n",
       "      <td>-0.030084</td>\n",
       "      <td>-0.040467</td>\n",
       "      <td>-0.052682</td>\n",
       "      <td>-0.035337</td>\n",
       "      <td>-0.062311</td>\n",
       "      <td>-0.051079</td>\n",
       "      <td>-0.017573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      word     emb_0     emb_1     emb_2  \\\n",
       "0           understated eyecatching design -0.019827 -0.006422  0.014570   \n",
       "3561                            usual gear  0.030396  0.048733  0.006757   \n",
       "2929                         banco popular -0.006136  0.053859 -0.027051   \n",
       "2297                              trekkies -0.027514  0.053677  0.028022   \n",
       "1665  harvard universitys t.h. chan school  0.019255  0.031570 -0.016233   \n",
       "\n",
       "         emb_3     emb_4     emb_5     emb_6     emb_7     emb_8  ...  \\\n",
       "0    -0.039300 -0.024002  0.054702  0.004713 -0.029246  0.004955  ...   \n",
       "3561  0.030050  0.014397 -0.028559  0.002080  0.052073 -0.000604  ...   \n",
       "2929  0.028665  0.007711  0.084763 -0.041701 -0.051199 -0.015713  ...   \n",
       "2297 -0.000125  0.069076 -0.055233  0.026868 -0.025693  0.007560  ...   \n",
       "1665 -0.085584 -0.027504  0.023182 -0.050383 -0.115471  0.063500  ...   \n",
       "\n",
       "       emb_502   emb_503   emb_504   emb_505   emb_506   emb_507   emb_508  \\\n",
       "0     0.070869 -0.036970 -0.019612 -0.023454  0.000452 -0.076762 -0.026164   \n",
       "3561 -0.043511  0.063861 -0.002875  0.009074  0.020639 -0.019907 -0.046328   \n",
       "2929  0.010460  0.015526  0.015577 -0.044722 -0.044955  0.021150 -0.029704   \n",
       "2297  0.037944  0.019393 -0.008219 -0.013544 -0.010799  0.046405 -0.019860   \n",
       "1665  0.034805 -0.001658  0.077751 -0.030084 -0.040467 -0.052682 -0.035337   \n",
       "\n",
       "       emb_509   emb_510   emb_511  \n",
       "0     0.079127 -0.016291  0.000221  \n",
       "3561  0.063082  0.022643  0.024093  \n",
       "2929 -0.033842 -0.046479  0.021843  \n",
       "2297  0.016044 -0.011341 -0.003216  \n",
       "1665 -0.062311 -0.051079 -0.017573  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w2v.iloc[::100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cl_number</th>\n",
       "      <th>cl_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>monthly service charge</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     word  cl_number  cl_size\n",
       "0  monthly service charge          0        7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "with open('./transition_files/df_result_'+str(52000)+'.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    df_res = pickle.load(f)\n",
    "df_res.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 176291 out of 419327\n",
      "(243036, 3) (176291, 513)\n"
     ]
    }
   ],
   "source": [
    "words_list = list(set(df_w2v['word']) - set(df_res['word']))\n",
    "print(\"Total number of words:\", len(words_list), \"out of\", len(df_w2v))\n",
    "df_tmp = df_w2v[df_w2v['word'].isin(words_list) == True]\n",
    "print(df_res.shape, df_tmp.shape)\n",
    "\n",
    "columns = [\"emb_\" + str(i) for i in range(512)]\n",
    "df_list = [df_res]\n",
    "cl_num = df_res['cl_number'].max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 176291 out of 419327\n",
      "(243036, 3) (176291, 513)\n",
      "\n",
      "TIME ELAPCED (in minutes): 8.44 53000\n",
      "Cluster number: 53000 \tCluster size: 2 \t 174063\n",
      "(245264, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 8.34 54000\n",
      "Cluster number: 54000 \tCluster size: 2 \t 171847\n",
      "(247480, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 8.23 55000\n",
      "Cluster number: 55000 \tCluster size: 1 \t 169680\n",
      "(249647, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 8.12 56000\n",
      "Cluster number: 56000 \tCluster size: 2 \t 167593\n",
      "(251734, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 8.04 57000\n",
      "Cluster number: 57000 \tCluster size: 3 \t 165483\n",
      "(253844, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 7.97 58000\n",
      "Cluster number: 58000 \tCluster size: 1 \t 163442\n",
      "(255885, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 7.87 59000\n",
      "Cluster number: 59000 \tCluster size: 1 \t 161517\n",
      "(257810, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 7.78 60000\n",
      "Cluster number: 60000 \tCluster size: 1 \t 159477\n",
      "(259850, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 8.51 61000\n",
      "Cluster number: 61000 \tCluster size: 1 \t 157438\n",
      "(261889, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 7.57 62000\n",
      "Cluster number: 62000 \tCluster size: 1 \t 155516\n",
      "(263811, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 7.48 63000\n",
      "Cluster number: 63000 \tCluster size: 1 \t 153574\n",
      "(265753, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 7.41 64000\n",
      "Cluster number: 64000 \tCluster size: 1 \t 151697\n",
      "(267630, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 7.3 65000\n",
      "Cluster number: 65000 \tCluster size: 2 \t 149814\n",
      "(269513, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 7.25 66000\n",
      "Cluster number: 66000 \tCluster size: 2 \t 147918\n",
      "(271409, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 7.23 67000\n",
      "Cluster number: 67000 \tCluster size: 2 \t 146017\n",
      "(273310, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 7.35 68000\n",
      "Cluster number: 68000 \tCluster size: 1 \t 144135\n",
      "(275192, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 7.14 69000\n",
      "Cluster number: 69000 \tCluster size: 2 \t 142331\n",
      "(276996, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 7.07 70000\n",
      "Cluster number: 70000 \tCluster size: 1 \t 140449\n",
      "(278878, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 6.96 71000\n",
      "Cluster number: 71000 \tCluster size: 1 \t 138695\n",
      "(280632, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 6.9 72000\n",
      "Cluster number: 72000 \tCluster size: 1 \t 136881\n",
      "(282446, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 6.85 73000\n",
      "Cluster number: 73000 \tCluster size: 1 \t 135080\n",
      "(284247, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 6.78 74000\n",
      "Cluster number: 74000 \tCluster size: 1 \t 133374\n",
      "(285953, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 24.44 75000\n",
      "Cluster number: 75000 \tCluster size: 1 \t 131619\n",
      "(287708, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 6.43 76000\n",
      "Cluster number: 76000 \tCluster size: 1 \t 129912\n",
      "(289415, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 6.35 77000\n",
      "Cluster number: 77000 \tCluster size: 1 \t 128231\n",
      "(291096, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 6.28 78000\n",
      "Cluster number: 78000 \tCluster size: 2 \t 126470\n",
      "(292857, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 6.17 79000\n",
      "Cluster number: 79000 \tCluster size: 2 \t 124817\n",
      "(294510, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 6.08 80000\n",
      "Cluster number: 80000 \tCluster size: 3 \t 123173\n",
      "(296154, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 6.02 81000\n",
      "Cluster number: 81000 \tCluster size: 2 \t 121522\n",
      "(297805, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 6.01 82000\n",
      "Cluster number: 82000 \tCluster size: 1 \t 119912\n",
      "(299415, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 5.93 83000\n",
      "Cluster number: 83000 \tCluster size: 1 \t 118266\n",
      "(301061, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 5.83 84000\n",
      "Cluster number: 84000 \tCluster size: 3 \t 116714\n",
      "(302613, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 5.74 85000\n",
      "Cluster number: 85000 \tCluster size: 1 \t 115114\n",
      "(304213, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 5.68 86000\n",
      "Cluster number: 86000 \tCluster size: 1 \t 113565\n",
      "(305762, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 5.64 87000\n",
      "Cluster number: 87000 \tCluster size: 2 \t 111997\n",
      "(307330, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 5.55 88000\n",
      "Cluster number: 88000 \tCluster size: 2 \t 110442\n",
      "(308885, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 5.44 89000\n",
      "Cluster number: 89000 \tCluster size: 1 \t 108914\n",
      "(310413, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 5.39 90000\n",
      "Cluster number: 90000 \tCluster size: 1 \t 107399\n",
      "(311928, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 5.34 91000\n",
      "Cluster number: 91000 \tCluster size: 1 \t 105897\n",
      "(313430, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 5.35 92000\n",
      "Cluster number: 92000 \tCluster size: 1 \t 104421\n",
      "(314906, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 5.32 93000\n",
      "Cluster number: 93000 \tCluster size: 1 \t 102935\n",
      "(316392, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 5.16 94000\n",
      "Cluster number: 94000 \tCluster size: 1 \t 101475\n",
      "(317852, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 5.05 95000\n",
      "Cluster number: 95000 \tCluster size: 2 \t 100049\n",
      "(319278, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 5.05 96000\n",
      "Cluster number: 96000 \tCluster size: 1 \t 98599\n",
      "(320728, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 5.01 97000\n",
      "Cluster number: 97000 \tCluster size: 1 \t 97190\n",
      "(322137, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.86 98000\n",
      "Cluster number: 98000 \tCluster size: 1 \t 95742\n",
      "(323585, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 20.51 99000\n",
      "Cluster number: 99000 \tCluster size: 2 \t 94293\n",
      "(325034, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.78 100000\n",
      "Cluster number: 100000 \tCluster size: 1 \t 92892\n",
      "(326435, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.72 101000\n",
      "Cluster number: 101000 \tCluster size: 1 \t 91458\n",
      "(327869, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.61 102000\n",
      "Cluster number: 102000 \tCluster size: 2 \t 90056\n",
      "(329271, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.52 103000\n",
      "Cluster number: 103000 \tCluster size: 1 \t 88676\n",
      "(330651, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.42 104000\n",
      "Cluster number: 104000 \tCluster size: 1 \t 87284\n",
      "(332043, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.37 105000\n",
      "Cluster number: 105000 \tCluster size: 2 \t 85917\n",
      "(333410, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.4 106000\n",
      "Cluster number: 106000 \tCluster size: 1 \t 84565\n",
      "(334762, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.32 107000\n",
      "Cluster number: 107000 \tCluster size: 1 \t 83192\n",
      "(336135, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.26 108000\n",
      "Cluster number: 108000 \tCluster size: 2 \t 81870\n",
      "(337457, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.16 109000\n",
      "Cluster number: 109000 \tCluster size: 1 \t 80522\n",
      "(338805, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.99 110000\n",
      "Cluster number: 110000 \tCluster size: 1 \t 79218\n",
      "(340109, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.93 111000\n",
      "Cluster number: 111000 \tCluster size: 1 \t 77886\n",
      "(341441, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.08 112000\n",
      "Cluster number: 112000 \tCluster size: 1 \t 76555\n",
      "(342772, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.57 113000\n",
      "Cluster number: 113000 \tCluster size: 1 \t 75228\n",
      "(344099, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 6.57 114000\n",
      "Cluster number: 114000 \tCluster size: 1 \t 73910\n",
      "(345417, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.66 115000\n",
      "Cluster number: 115000 \tCluster size: 3 \t 72584\n",
      "(346743, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.79 116000\n",
      "Cluster number: 116000 \tCluster size: 1 \t 71282\n",
      "(348045, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.36 117000\n",
      "Cluster number: 117000 \tCluster size: 1 \t 70000\n",
      "(349327, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.56 118000\n",
      "Cluster number: 118000 \tCluster size: 1 \t 68718\n",
      "(350609, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.61 119000\n",
      "Cluster number: 119000 \tCluster size: 1 \t 67457\n",
      "(351870, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.69 120000\n",
      "Cluster number: 120000 \tCluster size: 2 \t 66189\n",
      "(353138, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.54 121000\n",
      "Cluster number: 121000 \tCluster size: 1 \t 64915\n",
      "(354412, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.84 122000\n",
      "Cluster number: 122000 \tCluster size: 2 \t 63654\n",
      "(355673, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.15 123000\n",
      "Cluster number: 123000 \tCluster size: 1 \t 62403\n",
      "(356924, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.21 124000\n",
      "Cluster number: 124000 \tCluster size: 1 \t 61160\n",
      "(358167, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.16 125000\n",
      "Cluster number: 125000 \tCluster size: 1 \t 59925\n",
      "(359402, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.11 126000\n",
      "Cluster number: 126000 \tCluster size: 2 \t 58686\n",
      "(360641, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.61 127000\n",
      "Cluster number: 127000 \tCluster size: 1 \t 57460\n",
      "(361867, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.79 128000\n",
      "Cluster number: 128000 \tCluster size: 3 \t 56263\n",
      "(363064, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.86 129000\n",
      "Cluster number: 129000 \tCluster size: 1 \t 55035\n",
      "(364292, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.86 130000\n",
      "Cluster number: 130000 \tCluster size: 1 \t 53839\n",
      "(365488, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.4 131000\n",
      "Cluster number: 131000 \tCluster size: 1 \t 52626\n",
      "(366701, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 2.91 132000\n",
      "Cluster number: 132000 \tCluster size: 1 \t 51392\n",
      "(367935, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.46 133000\n",
      "Cluster number: 133000 \tCluster size: 1 \t 50227\n",
      "(369100, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.52 134000\n",
      "Cluster number: 134000 \tCluster size: 1 \t 49037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370290, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.57 135000\n",
      "Cluster number: 135000 \tCluster size: 1 \t 47843\n",
      "(371484, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.54 136000\n",
      "Cluster number: 136000 \tCluster size: 1 \t 46663\n",
      "(372664, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 2.94 137000\n",
      "Cluster number: 137000 \tCluster size: 1 \t 45513\n",
      "(373814, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 2.58 138000\n",
      "Cluster number: 138000 \tCluster size: 1 \t 44353\n",
      "(374974, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.03 139000\n",
      "Cluster number: 139000 \tCluster size: 1 \t 43166\n",
      "(376161, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.2 140000\n",
      "Cluster number: 140000 \tCluster size: 1 \t 42018\n",
      "(377309, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 3.06 141000\n",
      "Cluster number: 141000 \tCluster size: 1 \t 40865\n",
      "(378462, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 2.99 142000\n",
      "Cluster number: 142000 \tCluster size: 1 \t 39729\n",
      "(379598, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 4.02 143000\n",
      "Cluster number: 143000 \tCluster size: 1 \t 38596\n",
      "(380731, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 2.06 144000\n",
      "Cluster number: 144000 \tCluster size: 1 \t 37468\n",
      "(381859, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 2.42 145000\n",
      "Cluster number: 145000 \tCluster size: 1 \t 36325\n",
      "(383002, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 2.75 146000\n",
      "Cluster number: 146000 \tCluster size: 1 \t 35217\n",
      "(384110, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 2.79 147000\n",
      "Cluster number: 147000 \tCluster size: 1 \t 34094\n",
      "(385233, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 2.75 148000\n",
      "Cluster number: 148000 \tCluster size: 1 \t 32987\n",
      "(386340, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 2.56 149000\n",
      "Cluster number: 149000 \tCluster size: 1 \t 31856\n",
      "(387471, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 1.83 150000\n",
      "Cluster number: 150000 \tCluster size: 1 \t 30741\n",
      "(388586, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 17.04 151000\n",
      "Cluster number: 151000 \tCluster size: 1 \t 29639\n",
      "(389688, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 1.6 152000\n",
      "Cluster number: 152000 \tCluster size: 1 \t 28523\n",
      "(390804, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 1.52 153000\n",
      "Cluster number: 153000 \tCluster size: 1 \t 27433\n",
      "(391894, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 1.47 154000\n",
      "Cluster number: 154000 \tCluster size: 1 \t 26335\n",
      "(392992, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 1.42 155000\n",
      "Cluster number: 155000 \tCluster size: 1 \t 25241\n",
      "(394086, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 1.37 156000\n",
      "Cluster number: 156000 \tCluster size: 1 \t 24160\n",
      "(395167, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 1.33 157000\n",
      "Cluster number: 157000 \tCluster size: 1 \t 23085\n",
      "(396242, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 31.74 158000\n",
      "Cluster number: 158000 \tCluster size: 1 \t 22015\n",
      "(397312, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 14.66 159000\n",
      "Cluster number: 159000 \tCluster size: 1 \t 20943\n",
      "(398384, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 1.14 160000\n",
      "Cluster number: 160000 \tCluster size: 1 \t 19877\n",
      "(399450, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 1.12 161000\n",
      "Cluster number: 161000 \tCluster size: 1 \t 18805\n",
      "(400522, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 1.05 162000\n",
      "Cluster number: 162000 \tCluster size: 1 \t 17748\n",
      "(401579, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.99 163000\n",
      "Cluster number: 163000 \tCluster size: 1 \t 16691\n",
      "(402636, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.93 164000\n",
      "Cluster number: 164000 \tCluster size: 1 \t 15634\n",
      "(403693, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.86 165000\n",
      "Cluster number: 165000 \tCluster size: 1 \t 14575\n",
      "(404752, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.85 166000\n",
      "Cluster number: 166000 \tCluster size: 1 \t 13530\n",
      "(405797, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.8 167000\n",
      "Cluster number: 167000 \tCluster size: 1 \t 12482\n",
      "(406845, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.75 168000\n",
      "Cluster number: 168000 \tCluster size: 1 \t 11453\n",
      "(407874, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.67 169000\n",
      "Cluster number: 169000 \tCluster size: 1 \t 10417\n",
      "(408910, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.58 170000\n",
      "Cluster number: 170000 \tCluster size: 1 \t 9389\n",
      "(409938, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.55 171000\n",
      "Cluster number: 171000 \tCluster size: 1 \t 8358\n",
      "(410969, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.47 172000\n",
      "Cluster number: 172000 \tCluster size: 1 \t 7335\n",
      "(411992, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.42 173000\n",
      "Cluster number: 173000 \tCluster size: 2 \t 6313\n",
      "(413014, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.37 174000\n",
      "Cluster number: 174000 \tCluster size: 1 \t 5292\n",
      "(414035, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.31 175000\n",
      "Cluster number: 175000 \tCluster size: 1 \t 4281\n",
      "(415046, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.24 176000\n",
      "Cluster number: 176000 \tCluster size: 1 \t 3269\n",
      "(416058, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.2 177000\n",
      "Cluster number: 177000 \tCluster size: 1 \t 2260\n",
      "(417067, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.15 178000\n",
      "Cluster number: 178000 \tCluster size: 1 \t 1259\n",
      "(418068, 3)\n",
      "\n",
      "TIME ELAPCED (in minutes): 0.1 179000\n",
      "Cluster number: 179000 \tCluster size: 1 \t 257\n",
      "(419070, 3)\n"
     ]
    }
   ],
   "source": [
    "#this step took approximatelly 48h\n",
    "\n",
    "words_list = list(set(df_w2v['word']) - set(df_res['word']))\n",
    "print(\"Total number of words:\", len(words_list), \"out of\", len(df_w2v))\n",
    "df_tmp = df_w2v[df_w2v['word'].isin(words_list) == True]\n",
    "print(df_res.shape, df_tmp.shape)\n",
    "\n",
    "columns = [\"emb_\" + str(i) for i in range(512)]\n",
    "df_list = [df_res]\n",
    "cl_num = df_res['cl_number'].max() + 1\n",
    "\n",
    "start = time.time()\n",
    "while len(df_tmp)>0:\n",
    "    word = df_tmp['word'].iloc[0]\n",
    "    word_emb = df_tmp[df_tmp['word'] == word][columns].values\n",
    "    df_tmp[\"sim\"] = cosine_similarity(df_tmp[columns].values,word_emb)\n",
    "    df_tmp[\"sim\"] = df_tmp[\"sim\"].apply(np.abs)\n",
    "\n",
    "    df_cluster = df_tmp[df_tmp[\"sim\"] >= threshold]\n",
    "    df_cluster[\"cl_number\"] = cl_num\n",
    "    selected_words = list(df_cluster['word'])\n",
    "    df_cluster[\"cl_size\"] = len(selected_words)\n",
    "    df_list.append(df_cluster[['word', \"cl_number\", \"cl_size\"]])\n",
    "\n",
    "    df_tmp = df_tmp[df_tmp['word'].isin(selected_words) == False]\n",
    "    cl_num = cl_num + 1\n",
    "\n",
    "    if (cl_num % 1000) == 0:\n",
    "        finish = time.time()\n",
    "        print(\"\\nTIME ELAPCED (in minutes):\", round((finish-start)/60,2),cl_num)\n",
    "        print(\"Cluster number:\", cl_num, \"\\tCluster size:\", len(df_cluster), \"\\t\", len(df_tmp))\n",
    "        \n",
    "        df_result = pd.concat(df_list)\n",
    "        print(df_result.shape)\n",
    "        with open('./transition_files/df_result_'+str(cl_num)+'.pickle', 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(df_result, f, pickle.HIGHEST_PROTOCOL)\n",
    "        start = time.time()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419327, 3)\n"
     ]
    }
   ],
   "source": [
    "df_result = pd.concat(df_list)\n",
    "print(df_result.shape)\n",
    "with open('./transition_files/df_result.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(df_result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get cluster label as most frequent word/phrase of the cluster used in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419327, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cl_number</th>\n",
       "      <th>cl_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>monthly service charge</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     word  cl_number  cl_size\n",
       "0  monthly service charge          0        7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "with open('./transition_files/df_result.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    df_res = pickle.load(f)\n",
    "print(df_res.shape)\n",
    "df_res.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2092379\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>big emerging economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>steady march</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   word\n",
       "0                  rise\n",
       "1  big emerging economy\n",
       "2                 china\n",
       "3                 india\n",
       "4          steady march"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words =  all_NPs + all_Vs\n",
    "df_all_words = pd.DataFrame({'word': all_words})\n",
    "print(len(df_words))\n",
    "df_all_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2092379, 3)\n"
     ]
    }
   ],
   "source": [
    "df_all_words = df_all_words.merge(df_res, on='word', how='inner')\n",
    "print(df_all_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cl_number</th>\n",
       "      <th>cl_size</th>\n",
       "      <th>word_frequency</th>\n",
       "      <th>word_max_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rise</td>\n",
       "      <td>1486</td>\n",
       "      <td>20</td>\n",
       "      <td>795</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222220</th>\n",
       "      <td>detroit</td>\n",
       "      <td>1837</td>\n",
       "      <td>23</td>\n",
       "      <td>85</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444440</th>\n",
       "      <td>president trump</td>\n",
       "      <td>1171</td>\n",
       "      <td>38</td>\n",
       "      <td>276</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666660</th>\n",
       "      <td>hostility</td>\n",
       "      <td>31108</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888880</th>\n",
       "      <td>ink</td>\n",
       "      <td>15204</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111100</th>\n",
       "      <td>school bus</td>\n",
       "      <td>481</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333320</th>\n",
       "      <td>private new space company</td>\n",
       "      <td>219</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555540</th>\n",
       "      <td>pterodactyl</td>\n",
       "      <td>102039</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777760</th>\n",
       "      <td>needed</td>\n",
       "      <td>2311</td>\n",
       "      <td>42</td>\n",
       "      <td>812</td>\n",
       "      <td>2756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999980</th>\n",
       "      <td>monitors</td>\n",
       "      <td>51690</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              word  cl_number  cl_size  word_frequency  \\\n",
       "0                             rise       1486       20             795   \n",
       "222220                     detroit       1837       23              85   \n",
       "444440             president trump       1171       38             276   \n",
       "666660                   hostility      31108        4              20   \n",
       "888880                         ink      15204       11              29   \n",
       "1111100                 school bus        481       32              23   \n",
       "1333320  private new space company        219       17               1   \n",
       "1555540                pterodactyl     102039        3               1   \n",
       "1777760                     needed       2311       42             812   \n",
       "1999980                   monitors      51690        3              40   \n",
       "\n",
       "         word_max_frequency  \n",
       "0                       795  \n",
       "222220                  349  \n",
       "444440                  479  \n",
       "666660                   20  \n",
       "888880                   29  \n",
       "1111100                 130  \n",
       "1333320                   6  \n",
       "1555540                   1  \n",
       "1777760                2756  \n",
       "1999980                  40  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_words['word_frequency'] = df_all_words.groupby(['cl_number', 'word'])['word'].transform(\"count\")\n",
    "df_all_words['word_max_frequency'] = df_all_words.groupby(['cl_number'])['word_frequency'].transform(\"max\")\n",
    "df_all_words.iloc[::222220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>9%</th>\n",
       "      <th>10%</th>\n",
       "      <th>20%</th>\n",
       "      <th>30%</th>\n",
       "      <th>40%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cl_number</th>\n",
       "      <td>2092379.0</td>\n",
       "      <td>30647.862875</td>\n",
       "      <td>40231.480295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>3112.0</td>\n",
       "      <td>5376.0</td>\n",
       "      <td>8209.0</td>\n",
       "      <td>13151.0</td>\n",
       "      <td>40117.0</td>\n",
       "      <td>129618.0</td>\n",
       "      <td>167044.0</td>\n",
       "      <td>179256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cl_size</th>\n",
       "      <td>2092379.0</td>\n",
       "      <td>18.311795</td>\n",
       "      <td>27.750696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_frequency</th>\n",
       "      <td>2092379.0</td>\n",
       "      <td>840.679864</td>\n",
       "      <td>2361.341249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>3290.0</td>\n",
       "      <td>10360.0</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_max_frequency</th>\n",
       "      <td>2092379.0</td>\n",
       "      <td>963.430633</td>\n",
       "      <td>2440.771968</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>3477.0</td>\n",
       "      <td>20130.0</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count          mean           std  min     1%      9%  \\\n",
       "cl_number           2092379.0  30647.862875  40231.480295  0.0  131.0  1141.0   \n",
       "cl_size             2092379.0     18.311795     27.750696  1.0    1.0     1.0   \n",
       "word_frequency      2092379.0    840.679864   2361.341249  1.0    1.0     1.0   \n",
       "word_max_frequency  2092379.0    963.430633   2440.771968  1.0    1.0     2.0   \n",
       "\n",
       "                       10%     20%     30%     40%      50%      75%  \\\n",
       "cl_number           1242.0  3112.0  5376.0  8209.0  13151.0  40117.0   \n",
       "cl_size                2.0     3.0     5.0     7.0     10.0     23.0   \n",
       "word_frequency         1.0     3.0    13.0    46.0    122.0    694.0   \n",
       "word_max_frequency     2.0     9.0    34.0    92.0    206.0    927.0   \n",
       "\n",
       "                         95%       99%       max  \n",
       "cl_number           129618.0  167044.0  179256.0  \n",
       "cl_size                 60.0     114.0     513.0  \n",
       "word_frequency        3290.0   10360.0   20130.0  \n",
       "word_max_frequency    3477.0   20130.0   20130.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_all_words.describe(percentiles=[0.01,0.09, 0.1,0.20,0.3,0.4,0.5,0.75,0.95,0.99])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179257, 3)\n"
     ]
    }
   ],
   "source": [
    "df_cl_labeled = df_all_words[df_all_words['word_max_frequency'] == df_all_words['word_frequency']]\n",
    "df_cl_labeled['cluster_label'] = df_cl_labeled['word']\n",
    "df_cl_labeled = df_cl_labeled.groupby('cl_number')[['cluster_label','cl_size']].last().reset_index()\n",
    "print(df_cl_labeled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cl_number</th>\n",
       "      <th>cluster_label</th>\n",
       "      <th>cl_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>monthly fee</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15500</th>\n",
       "      <td>15500</td>\n",
       "      <td>akerman</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31000</th>\n",
       "      <td>31000</td>\n",
       "      <td>frustrated swiss bank</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46500</th>\n",
       "      <td>46500</td>\n",
       "      <td>company cofounder tim brown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62000</th>\n",
       "      <td>62000</td>\n",
       "      <td>trappist1 systema</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77500</th>\n",
       "      <td>77500</td>\n",
       "      <td>best institution</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93000</th>\n",
       "      <td>93000</td>\n",
       "      <td>governments book</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108500</th>\n",
       "      <td>108500</td>\n",
       "      <td>takashi takano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124000</th>\n",
       "      <td>124000</td>\n",
       "      <td>fixed chronic airflow obstruction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139500</th>\n",
       "      <td>139500</td>\n",
       "      <td>nonstopon conference panel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155000</th>\n",
       "      <td>155000</td>\n",
       "      <td>darkis</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170500</th>\n",
       "      <td>170500</td>\n",
       "      <td>staged car theft</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cl_number                      cluster_label  cl_size\n",
       "0               0                        monthly fee        7\n",
       "15500       15500                            akerman        3\n",
       "31000       31000              frustrated swiss bank        2\n",
       "46500       46500        company cofounder tim brown        1\n",
       "62000       62000                  trappist1 systema        1\n",
       "77500       77500                   best institution        1\n",
       "93000       93000                   governments book        1\n",
       "108500     108500                     takashi takano        1\n",
       "124000     124000  fixed chronic airflow obstruction        1\n",
       "139500     139500         nonstopon conference panel        1\n",
       "155000     155000                             darkis        3\n",
       "170500     170500                   staged car theft        1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cl_labeled.iloc[::15500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2092379, 2)\n",
      "(419327, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>222222</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>rise</td>\n",
       "      <td>preliminary budget proposal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cl_number</th>\n",
       "      <td>1486</td>\n",
       "      <td>12841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_label</th>\n",
       "      <td>rise</td>\n",
       "      <td>initial proposal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cl_size</th>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                            222222\n",
       "word            rise  preliminary budget proposal\n",
       "cl_number       1486                        12841\n",
       "cluster_label   rise             initial proposal\n",
       "cl_size           20                            7"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_clusters = df_all_words[['word', 'cl_number']]\n",
    "print(df_word_clusters.shape)\n",
    "\n",
    "df_word_clusters = df_word_clusters.drop_duplicates()\n",
    "df_word_clusters = df_word_clusters.merge(df_cl_labeled, on='cl_number', how='inner')\n",
    "\n",
    "print(df_word_clusters.shape)\n",
    "df_word_clusters.iloc[::222222].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cl_number</th>\n",
       "      <th>cluster_label</th>\n",
       "      <th>cl_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222222</th>\n",
       "      <td>preliminary budget proposal</td>\n",
       "      <td>12841</td>\n",
       "      <td>initial proposal</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222223</th>\n",
       "      <td>initial proposal</td>\n",
       "      <td>12841</td>\n",
       "      <td>initial proposal</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222224</th>\n",
       "      <td>launch service agreement proposal</td>\n",
       "      <td>12841</td>\n",
       "      <td>initial proposal</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222225</th>\n",
       "      <td>contract proposal</td>\n",
       "      <td>12841</td>\n",
       "      <td>initial proposal</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222226</th>\n",
       "      <td>initial deal</td>\n",
       "      <td>12841</td>\n",
       "      <td>initial proposal</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222227</th>\n",
       "      <td>initial contract proposal</td>\n",
       "      <td>12841</td>\n",
       "      <td>initial proposal</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222228</th>\n",
       "      <td>initial offer</td>\n",
       "      <td>12841</td>\n",
       "      <td>initial proposal</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     word  cl_number     cluster_label  \\\n",
       "222222        preliminary budget proposal      12841  initial proposal   \n",
       "222223                   initial proposal      12841  initial proposal   \n",
       "222224  launch service agreement proposal      12841  initial proposal   \n",
       "222225                  contract proposal      12841  initial proposal   \n",
       "222226                       initial deal      12841  initial proposal   \n",
       "222227          initial contract proposal      12841  initial proposal   \n",
       "222228                      initial offer      12841  initial proposal   \n",
       "\n",
       "        cl_size  \n",
       "222222        7  \n",
       "222223        7  \n",
       "222224        7  \n",
       "222225        7  \n",
       "222226        7  \n",
       "222227        7  \n",
       "222228        7  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_clusters[df_word_clusters['cl_number'] == 12841]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_clusters.to_csv('./transition_files/word_cluster_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Replace text words with their cluster names (KeyWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'author', 'title', 'url', 'section', 'publication',\n",
       "       'first_10_sents', 'list_of_first_10_sents', 'list_of_verb_lemmas',\n",
       "       'noun_phrases', 'list_of_nouns', 'list_of_lemmas', 'ID',\n",
       "       'group_level_1', 'group_level_2', 'group_level_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['all_words'] = df_train['list_of_verb_lemmas'] + df_train['noun_phrases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cluster_label_dict =dict(zip(df_word_clusters['word'], df_word_clusters['cluster_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_key_words</th>\n",
       "      <th>all_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[merge, led, looking, travel, granted, upgrade, travel, apply, post, streamline, scra, rise, emerging economy, china, india, steady march, globali...</td>\n",
       "      <td>[merging, led, wanting, travel, granted, upgrade, travel, apply, submit, streamline, scra, rise, big emerging economy, china, india, steady march,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[rided, embracing, denied, gain, reduce, upgrade, desire, looking, aimed, shift, domiciled, joy, save, pay, puzzled, promise, asks, engage, sugges...</td>\n",
       "      <td>[rided, embracing, insists, gain, strengthen, improve, deterred, seeking, intends, shift, domiciled, rejoiced, saved, paid, outraged, promised, im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[aised, stop, celebrate, trying, lift, forced, reverse, cut, help, understand, upgrade, strike, wish, save, spend, try, escape, slashed, encourage...</td>\n",
       "      <td>[aised, ended, celebrate, tried, lift, forced, reverse, cut, help, understand, upgrade, strike, wish, save, spend, try, escape, slashing, encourag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[race, reserved, upgrade, told, control, demand, peaking, piling, based, got, moving, upgrade, increase, told, created, aimed, based, buy, cruise,...</td>\n",
       "      <td>[race, booked, improve, announced, control, demand, peaking, piling, based, got, moving, upgrade, increase, announced, establish, aimed, based, ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[tart, caught, prove, reflected, like, suggest, judged, betting, expected, upgrade, disrupt, getting, push, tighten, buy, priced, doubt, tighten, ...</td>\n",
       "      <td>[tart, caught, proved, reflected, like, suggest, judged, betting, expect, upgrade, weakens, having, pushed, tighten, buy, priced, doubt, tighten, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           all_key_words  \\\n",
       "0  [merge, led, looking, travel, granted, upgrade, travel, apply, post, streamline, scra, rise, emerging economy, china, india, steady march, globali...   \n",
       "1  [rided, embracing, denied, gain, reduce, upgrade, desire, looking, aimed, shift, domiciled, joy, save, pay, puzzled, promise, asks, engage, sugges...   \n",
       "2  [aised, stop, celebrate, trying, lift, forced, reverse, cut, help, understand, upgrade, strike, wish, save, spend, try, escape, slashed, encourage...   \n",
       "3  [race, reserved, upgrade, told, control, demand, peaking, piling, based, got, moving, upgrade, increase, told, created, aimed, based, buy, cruise,...   \n",
       "4  [tart, caught, prove, reflected, like, suggest, judged, betting, expected, upgrade, disrupt, getting, push, tighten, buy, priced, doubt, tighten, ...   \n",
       "\n",
       "                                                                                                                                               all_words  \n",
       "0  [merging, led, wanting, travel, granted, upgrade, travel, apply, submit, streamline, scra, rise, big emerging economy, china, india, steady march,...  \n",
       "1  [rided, embracing, insists, gain, strengthen, improve, deterred, seeking, intends, shift, domiciled, rejoiced, saved, paid, outraged, promised, im...  \n",
       "2  [aised, ended, celebrate, tried, lift, forced, reverse, cut, help, understand, upgrade, strike, wish, save, spend, try, escape, slashing, encourag...  \n",
       "3  [race, booked, improve, announced, control, demand, peaking, piling, based, got, moving, upgrade, increase, announced, establish, aimed, based, ad...  \n",
       "4  [tart, caught, proved, reflected, like, suggest, judged, betting, expect, upgrade, weakens, having, pushed, tighten, buy, priced, doubt, tighten, ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['all_key_words'] = df_train['all_words'].apply(lambda Wlist: \n",
    "                                                        [word_cluster_label_dict[w] for w in  Wlist\n",
    "                                                                                    if w in word_cluster_label_dict\n",
    "                                                        ])\n",
    "df_train[['all_key_words', 'all_words']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eld', 'featuring', 'held', 'attending', 'companieswere', 'tied', 'holding', 'minted', 'set', 'gruelling', 'likened', 'speeddating', 'review', 'seen', 'looking', 'plan', 'grill', 'inviting', 'visit', 'meet', 'upgrad', 'american economic associations annual conference', 'gigantic teachin', 'lot', 'seminar', 'famous economist', 'threeday event', 'san francisco', 'employersboth university', 'hotel room', 'marathon interview session', 'freshly minted phds', 'ballroom', 'marriott', 'candidate', 'exhausted phd', 'recruiter', 'end', 'day', 'alan green', 'christopher de bodisco', 'stetson university', 'small private college', 'florida', 'candidate', 'interest', 'health', 'development', 'dozen candidate', 'promising one', 'campus', 'rest', 'faculty', 'inbox', 'daily dispatch', 'editors']\n",
      "==================================================\n",
      "['eld', 'involving', 'held', 'going', 'companieswere', 'tied', 'held', 'minted', 'set', 'gruelling', 'comparison', 'speeddating', 'consider', 'seen', 'looking', 'plan', 'grill', 'invited', 'visit', 'meet', 'upgrad', 'american public health association', 'gigantic teachin', 'lot', 'seminar', 'economists', 'twoday event', 'san francisco', 'keio university', 'room', 'marathon interview session', 'freshly minted phds', 'ballroom', 'marriott', 'candidate', 'grad student', 'enlist', 'end', 'day', 'alan ferguson', 'christopher bonanos', 'stetson university', 'small school', 'florida', 'candidate', 'interest', 'health', 'development', 'dozen candidate', 'promising one', 'campus', 'rest', 'mit', 'inbox', 'daily dispatch', 'editors']\n"
     ]
    }
   ],
   "source": [
    "ind = 10\n",
    "print(df_train['all_words'].iloc[ind])\n",
    "print(\"=\"*50)\n",
    "print(df_train['all_key_words'].iloc[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./transition_files/df_train_for_LDA.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(df_train, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GLG - 3_step - Assigning Text Groups.ipynb",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.45px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
