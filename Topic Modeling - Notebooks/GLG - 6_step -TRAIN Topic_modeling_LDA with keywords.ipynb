{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea:\n",
    "Our solution: LDA + keywords from clusters of BERT based embeddings of noun phrases and verbs :\n",
    "- Each noun phrase and verb in the texts is  transformed to embedding vector using Universal Sentence Encoder (transformer based on BERT)\n",
    "- Embedding vectors from (a) are grouped into clusters with cosign similarity >= 70%\n",
    "- Words/phrases with embedding vectors closest to the centers of resulting clusters form key word/phrase\n",
    "- Each text in the training sample is converted to collection of key-phrases by replacing its noun phrases and verbs with keyword/phrases and deleting other words\n",
    "- LDA is performed on the transformed texts\n",
    "\n",
    "\n",
    "**Reference:**<br>\n",
    "- Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Constant, Mario Guajardo-CÃ©spedes, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil. **Universal Sentence Encoder.** *arXiv:1803.11175, 2018.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clNUUp3MUO2t"
   },
   "source": [
    "# Load data and python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1622131163361,
     "user": {
      "displayName": "Tatiana Chebonenko",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgwGu7u_TizJ74HmaMD0AtIfiksMdhRYrfZtevXzQ=s64",
      "userId": "10264586744881678851"
     },
     "user_tz": 240
    },
    "id": "7dYQIbH6UO2u"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tatiana/opt/anaconda3/lib/python3.7/site-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n",
      "/Users/tatiana/opt/anaconda3/lib/python3.7/site-packages/past/builtins/misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping\n",
      "/Users/tatiana/opt/anaconda3/lib/python3.7/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n",
      "INFO:absl:Using /var/folders/96/lvl2l9k91mqbyk2328hjtzg40000gn/T/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# topic modeling libraries\n",
    "import pyLDAvis.gensim \n",
    "\n",
    "# data visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# topic modeling libraries\n",
    "from gensim import models, corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "\n",
    "# supporting libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import topic_modeling_v4 as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape: (33982, 18)\n",
      "df_train.columns: Index(['date', 'author', 'title', 'url', 'section', 'publication',\n",
      "       'first_10_sents', 'list_of_first_10_sents', 'list_of_verb_lemmas',\n",
      "       'noun_phrases', 'list_of_nouns', 'list_of_lemmas', 'ID',\n",
      "       'group_level_1', 'group_level_2', 'group_level_3', 'all_words',\n",
      "       'all_key_words'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "with open(\"./transition_files/df_train_for_LDA.pickle\", 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    df_train = pickle.load(f)\n",
    "\n",
    "print(\"df_train.shape:\", df_train.shape)\n",
    "print(\"df_train.columns:\",df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data shape: (33982, 18)\n",
      "\n",
      "Number of unique key-words for topic modeling dictionary: 179256\n",
      "LDA dictionary file is saved to: ./output/lda_keywords/dictionary1.pickle\n",
      "\n",
      "Number of texts processed:  33982\n",
      "Number of extracted key-words:  179256\n",
      "\n",
      "Each text is represented by list of  179256  tuples: \n",
      "\t\t(key-words's index in bag-of-words dictionary, key-words's term frequency)\n",
      "Processing time in minutes: 0.08\n"
     ]
    }
   ],
   "source": [
    "#prepare data for LDA\n",
    "start_time = time.time()\n",
    "df_data_1 = tm.prepare_for_modeling(data_path=\"\", model_type=\"LDA-KeyWords\",\n",
    "                                    params={\"TEXT_prepared_df\": df_train,\n",
    "                                     \"save_LDA_dictionary_path\": \"./output/lda_keywords/dictionary1.pickle\",\n",
    "                                     \"words_column\": \"all_key_words\"\n",
    "                                     },\n",
    "                                    verbose=2)\n",
    "end_time = time.time()\n",
    "print(\"Processing time in minutes:\", round((end_time - start_time)/60,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "loaded data shape: (33982, 19)\n",
      "\n",
      "Creating document-term matrix for LDA...\n",
      "\n",
      "Training LDA model with  10  topics...\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1\n",
      "Top topic indexes are selected. NOTE \"-1\" corresponds to top topic with probability < 20%\n",
      "Processing time in minutes: 2.0\n"
     ]
    }
   ],
   "source": [
    "#first level of topics\n",
    "start_time = time.time()\n",
    "df_first_level = tm.train_model(model_type=\"LDA-KeyWords\",\n",
    "                            params={\"num_topics\": 10,\n",
    "                                    \"LDA_prepared_df\": df_data_1,\n",
    "                                    \"LDA_dictionary_path\": \"./output/lda_keywords/dictionary1.pickle\",\n",
    "                                    \"save_LDA_model_path\": \"./output/lda_keywords/LDA_model1\"\n",
    "                                    },\n",
    "                               verbose=2)\n",
    "end_time = time.time()\n",
    "print(\"Processing time in minutes:\", round((end_time - start_time)/60,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1027\n",
       "1    3960\n",
       "2    2721\n",
       "3    7666\n",
       "4    1173\n",
       "5    4288\n",
       "6    4312\n",
       "7    3756\n",
       "8    1449\n",
       "9    3630\n",
       "Name: first_level_topic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value count of TOP level topics\n",
    "df_first_level['first_level_topic'] = df_first_level['top_topic']\n",
    "df_first_level['first_level_topic_proba'] = df_first_level['top_topic_proba']\n",
    "df_first_level['first_level_topic'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'author', 'title', 'url', 'section', 'publication',\n",
       "       'first_10_sents', 'list_of_first_10_sents', 'list_of_verb_lemmas',\n",
       "       'noun_phrases', 'list_of_nouns', 'list_of_lemmas', 'ID',\n",
       "       'group_level_1', 'group_level_2', 'group_level_3', 'all_words',\n",
       "       'all_key_words', 'doc2bow', 'infered_topics', 'top_topic',\n",
       "       'top_topic_proba', 'first_level_topic', 'first_level_topic_proba'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first_level.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_first_level[df_first_level['first_level_topic'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_first_level[df_first_level['first_level_topic'] == 0]['first_10_sents'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_first_level[df_first_level['first_level_topic'] == 0]['all_key_words'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_level = df_first_level.drop(columns=['doc2bow',\n",
    "       'infered_topics', 'top_topic', 'top_topic_proba'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Get SECOND level topics (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_level_topics = list(set(df_first_level['first_level_topic']))\n",
    "first_level_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected topic index: 0\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_1\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    167\n",
      "1    195\n",
      "2    235\n",
      "3    143\n",
      "4    287\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 1\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_2\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0     508\n",
      "1     683\n",
      "2     958\n",
      "3     800\n",
      "4    1011\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 2\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_3\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    575\n",
      "1    808\n",
      "2    380\n",
      "3    424\n",
      "4    534\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 3\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_4\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    2147\n",
      "1    2073\n",
      "2    1267\n",
      "3     758\n",
      "4    1421\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 4\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_5\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    314\n",
      "1    201\n",
      "2    241\n",
      "3    251\n",
      "4    166\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 5\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_6\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0     823\n",
      "1    1141\n",
      "2     401\n",
      "3    1035\n",
      "4     888\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 6\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_7\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0     318\n",
      "1     593\n",
      "2    1454\n",
      "3     664\n",
      "4    1283\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 7\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_8\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0     561\n",
      "1     800\n",
      "2     753\n",
      "3     575\n",
      "4    1067\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 8\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_9\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0    241\n",
      "1    341\n",
      "2    384\n",
      "3    231\n",
      "4    252\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected topic index: 9\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_10\n",
      "\n",
      "Value counts of SECOND level topics:\n",
      "0     397\n",
      "1     602\n",
      "2     465\n",
      "3    1672\n",
      "4     494\n",
      "Name: second_level_topic, dtype: int64\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "list_dfs = []\n",
    "for topic in first_level_topics:\n",
    "    print(\"\\nSelected topic index:\", topic)\n",
    "    df_topic = df_first_level[df_first_level['first_level_topic'] == topic].copy()\n",
    "    save_dict_path = \"./output/lda_keywords/dictionary1_\"+str(topic+1)+\".pickle\"\n",
    "    save_LDA_model_path = \"./output/lda_keywords/LDA_model1_\" + str(topic + 1)\n",
    "    \n",
    "    df_data_tmp = tm.prepare_for_modeling(data_path=\"\", model_type=\"LDA-KeyWords\",\n",
    "                                       params={\"TEXT_prepared_df\": df_topic,\n",
    "                                               \"save_LDA_dictionary_path\": save_dict_path,\n",
    "                                               \"words_column\": \"all_key_words\"\n",
    "                                               },\n",
    "                                       verbose=1)\n",
    "\n",
    "    df_2nd_tmp = tm.train_model(model_type=\"LDA-KeyWords\",\n",
    "                                params={\"num_topics\": 5,\n",
    "                                        \"LDA_prepared_df\": df_data_tmp,\n",
    "                                        \"LDA_dictionary_path\": save_dict_path,\n",
    "                                        \"save_LDA_model_path\": save_LDA_model_path\n",
    "                                        },\n",
    "                                verbose=1)\n",
    "\n",
    "    #value counts of SECOND level topics\n",
    "    print(\"\\nValue counts of SECOND level topics:\")\n",
    "    df_2nd_tmp['second_level_topic'] = df_2nd_tmp['top_topic']\n",
    "    df_2nd_tmp['second_level_topic_proba'] = df_2nd_tmp['top_topic_proba']\n",
    "    print(df_2nd_tmp['second_level_topic'].value_counts().sort_index())\n",
    "\n",
    "    print(\"#\"*50)\n",
    "    df_2nd_tmp = df_2nd_tmp.drop(columns=['doc2bow',\n",
    "                                           'infered_topics', 'top_topic', 'top_topic_proba'])\n",
    "    list_dfs.append(df_2nd_tmp)\n",
    "finish = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of gettig Second level topics in minutes: 7.29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['date', 'author', 'title', 'url', 'section', 'publication',\n",
       "       'first_10_sents', 'list_of_first_10_sents', 'list_of_verb_lemmas',\n",
       "       'noun_phrases', 'list_of_nouns', 'list_of_lemmas', 'ID',\n",
       "       'group_level_1', 'group_level_2', 'group_level_3', 'all_words',\n",
       "       'all_key_words', 'first_level_topic', 'first_level_topic_proba',\n",
       "       'second_level_topic', 'second_level_topic_proba'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Time of gettig Second level topics in minutes:\", round((finish-start)/60,2))\n",
    "df_second_level = pd.concat(list_dfs)\n",
    "df_second_level.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Get THIRD level topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_level_topic</th>\n",
       "      <th>first_level_topic_proba</th>\n",
       "      <th>second_level_topic</th>\n",
       "      <th>second_level_topic_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33982.000000</td>\n",
       "      <td>33982.000000</td>\n",
       "      <td>33982.000000</td>\n",
       "      <td>33982.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.560002</td>\n",
       "      <td>0.721855</td>\n",
       "      <td>2.053558</td>\n",
       "      <td>0.864971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.597325</td>\n",
       "      <td>0.196475</td>\n",
       "      <td>1.411574</td>\n",
       "      <td>0.172679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.556901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.711267</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.980011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.918785</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.987249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.991813</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.992658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_level_topic  first_level_topic_proba  second_level_topic  \\\n",
       "count       33982.000000             33982.000000        33982.000000   \n",
       "mean            4.560002                 0.721855            2.053558   \n",
       "std             2.597325                 0.196475            1.411574   \n",
       "min             0.000000                 0.211725            0.000000   \n",
       "25%             3.000000                 0.556901            1.000000   \n",
       "50%             5.000000                 0.711267            2.000000   \n",
       "75%             7.000000                 0.918785            3.000000   \n",
       "max             9.000000                 0.991813            4.000000   \n",
       "\n",
       "       second_level_topic_proba  \n",
       "count              33982.000000  \n",
       "mean                   0.864971  \n",
       "std                    0.172679  \n",
       "min                    0.278245  \n",
       "25%                    0.733245  \n",
       "50%                    0.980011  \n",
       "75%                    0.987249  \n",
       "max                    0.992658  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_second_level[['first_level_topic',\n",
    "       'first_level_topic_proba', 'second_level_topic',\n",
    "       'second_level_topic_proba']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected FIRST level topic index: 0\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (0, 0)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_1_1\n",
      "Value counts of THIRD level topics:\n",
      "0    55\n",
      "1    50\n",
      "2    62\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (0, 1)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_1_2\n",
      "Value counts of THIRD level topics:\n",
      "0    73\n",
      "1    68\n",
      "2    54\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (0, 2)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_1_3\n",
      "Value counts of THIRD level topics:\n",
      "0    65\n",
      "1    91\n",
      "2    79\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (0, 3)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_1_4\n",
      "Value counts of THIRD level topics:\n",
      "0    50\n",
      "1    42\n",
      "2    51\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (0, 4)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_1_5\n",
      "Value counts of THIRD level topics:\n",
      "0    111\n",
      "1    103\n",
      "2     73\n",
      "Name: third_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 1\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (1, 0)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_2_1\n",
      "Value counts of THIRD level topics:\n",
      "0    136\n",
      "1    174\n",
      "2    198\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (1, 1)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_2_2\n",
      "Value counts of THIRD level topics:\n",
      "0    183\n",
      "1    227\n",
      "2    273\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (1, 2)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_2_3\n",
      "Value counts of THIRD level topics:\n",
      "0    323\n",
      "1    174\n",
      "2    461\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (1, 3)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_2_4\n",
      "Value counts of THIRD level topics:\n",
      "0    116\n",
      "1    214\n",
      "2    470\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (1, 4)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_2_5\n",
      "Value counts of THIRD level topics:\n",
      "0    297\n",
      "1    367\n",
      "2    347\n",
      "Name: third_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 2\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (2, 0)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_3_1\n",
      "Value counts of THIRD level topics:\n",
      "0    142\n",
      "1    141\n",
      "2    292\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (2, 1)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_3_2\n",
      "Value counts of THIRD level topics:\n",
      "0    253\n",
      "1    265\n",
      "2    290\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (2, 2)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_3_3\n",
      "Value counts of THIRD level topics:\n",
      "0    107\n",
      "1    108\n",
      "2    165\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (2, 3)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_3_4\n",
      "Value counts of THIRD level topics:\n",
      "0    135\n",
      "1    139\n",
      "2    150\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (2, 4)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_3_5\n",
      "Value counts of THIRD level topics:\n",
      "0    180\n",
      "1    186\n",
      "2    168\n",
      "Name: third_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 3\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (3, 0)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_4_1\n",
      "Value counts of THIRD level topics:\n",
      "0     796\n",
      "1     212\n",
      "2    1139\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (3, 1)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_4_2\n",
      "Value counts of THIRD level topics:\n",
      "0    752\n",
      "1    745\n",
      "2    576\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (3, 2)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_4_3\n",
      "Value counts of THIRD level topics:\n",
      "0    593\n",
      "1    314\n",
      "2    360\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (3, 3)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_4_4\n",
      "Value counts of THIRD level topics:\n",
      "0    240\n",
      "1    184\n",
      "2    334\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (3, 4)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_4_5\n",
      "Value counts of THIRD level topics:\n",
      "0    534\n",
      "1    598\n",
      "2    289\n",
      "Name: third_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 4\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (4, 0)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_5_1\n",
      "Value counts of THIRD level topics:\n",
      "0     70\n",
      "1    102\n",
      "2    142\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (4, 1)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_5_2\n",
      "Value counts of THIRD level topics:\n",
      "0    72\n",
      "1    61\n",
      "2    68\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (4, 2)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_5_3\n",
      "Value counts of THIRD level topics:\n",
      "0    77\n",
      "1    80\n",
      "2    84\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (4, 3)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_5_4\n",
      "Value counts of THIRD level topics:\n",
      "0    94\n",
      "1    94\n",
      "2    63\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (4, 4)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_5_5\n",
      "Value counts of THIRD level topics:\n",
      "0    54\n",
      "1    61\n",
      "2    51\n",
      "Name: third_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 5\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (5, 0)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_6_1\n",
      "Value counts of THIRD level topics:\n",
      "0    296\n",
      "1    149\n",
      "2    378\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (5, 1)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_6_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts of THIRD level topics:\n",
      "0    468\n",
      "1    260\n",
      "2    413\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (5, 2)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_6_3\n",
      "Value counts of THIRD level topics:\n",
      "0    146\n",
      "1    111\n",
      "2    144\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (5, 3)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_6_4\n",
      "Value counts of THIRD level topics:\n",
      "0    240\n",
      "1    271\n",
      "2    524\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (5, 4)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_6_5\n",
      "Value counts of THIRD level topics:\n",
      "0    279\n",
      "1    193\n",
      "2    416\n",
      "Name: third_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 6\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (6, 0)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_7_1\n",
      "Value counts of THIRD level topics:\n",
      "0     83\n",
      "1    127\n",
      "2    108\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (6, 1)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_7_2\n",
      "Value counts of THIRD level topics:\n",
      "0    204\n",
      "1    178\n",
      "2    211\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (6, 2)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_7_3\n",
      "Value counts of THIRD level topics:\n",
      "0    485\n",
      "1    332\n",
      "2    637\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (6, 3)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_7_4\n",
      "Value counts of THIRD level topics:\n",
      "0    249\n",
      "1    205\n",
      "2    210\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (6, 4)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_7_5\n",
      "Value counts of THIRD level topics:\n",
      "0    290\n",
      "1    521\n",
      "2    472\n",
      "Name: third_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 7\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (7, 0)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_8_1\n",
      "Value counts of THIRD level topics:\n",
      "0    185\n",
      "1    174\n",
      "2    202\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (7, 1)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_8_2\n",
      "Value counts of THIRD level topics:\n",
      "0    213\n",
      "1    254\n",
      "2    333\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (7, 2)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_8_3\n",
      "Value counts of THIRD level topics:\n",
      "0    241\n",
      "1    240\n",
      "2    272\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (7, 3)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_8_4\n",
      "Value counts of THIRD level topics:\n",
      "0    169\n",
      "1    179\n",
      "2    227\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (7, 4)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_8_5\n",
      "Value counts of THIRD level topics:\n",
      "0    385\n",
      "1    327\n",
      "2    355\n",
      "Name: third_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 8\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (8, 0)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_9_1\n",
      "Value counts of THIRD level topics:\n",
      "0    90\n",
      "1    94\n",
      "2    57\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (8, 1)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_9_2\n",
      "Value counts of THIRD level topics:\n",
      "0    122\n",
      "1     97\n",
      "2    122\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (8, 2)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_9_3\n",
      "Value counts of THIRD level topics:\n",
      "0    136\n",
      "1     91\n",
      "2    157\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (8, 3)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_9_4\n",
      "Value counts of THIRD level topics:\n",
      "0    69\n",
      "1    96\n",
      "2    66\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (8, 4)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_9_5\n",
      "Value counts of THIRD level topics:\n",
      "0    101\n",
      "1     79\n",
      "2     72\n",
      "Name: third_level_topic, dtype: int64\n",
      "##################################################\n",
      "\n",
      "Selected FIRST level topic index: 9\n",
      "second_level_topics [0, 1, 2, 3, 4]\n",
      "\n",
      "Selected topics' indexes: (9, 0)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_10_1\n",
      "Value counts of THIRD level topics:\n",
      "0    120\n",
      "1    142\n",
      "2    135\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (9, 1)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_10_2\n",
      "Value counts of THIRD level topics:\n",
      "0    189\n",
      "1    203\n",
      "2    210\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (9, 2)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_10_3\n",
      "Value counts of THIRD level topics:\n",
      "0    153\n",
      "1    144\n",
      "2    168\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (9, 3)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_10_4\n",
      "Value counts of THIRD level topics:\n",
      "0    421\n",
      "1    743\n",
      "2    508\n",
      "Name: third_level_topic, dtype: int64\n",
      "\n",
      "Selected topics' indexes: (9, 4)\n",
      "Training LDA with semantically similar clusteres ow words (NOUN_PHRASEs and VERBs)\n",
      "LDA model file is saved to: ./output/lda_keywords/LDA_model1_10_5\n",
      "Value counts of THIRD level topics:\n",
      "0    138\n",
      "1    192\n",
      "2    164\n",
      "Name: third_level_topic, dtype: int64\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "list_dfs = []\n",
    "\n",
    "for topic_1st in first_level_topics:\n",
    "    print(\"\\nSelected FIRST level topic index:\",topic_1st)\n",
    "    df_1st_tmp = df_second_level[df_second_level['first_level_topic'] == topic_1st].copy()\n",
    "    second_level_topics = list(set(df_1st_tmp['second_level_topic']))\n",
    "    print(\"second_level_topics\", second_level_topics)\n",
    "    \n",
    "    for topic_2nd in second_level_topics:\n",
    "        print(\"\\nSelected topics' indexes:\", (topic_1st, topic_2nd))\n",
    "        \n",
    "        save_dict_path = \"./output/lda_keywords/dictionary1_\"+str(topic_1st+1)+\"_\"+str(topic_2nd+1)+\".pickle\"\n",
    "        save_LDA_model_path = \"./output/lda_keywords/LDA_model1_\"+str(topic_1st+1)+\"_\"+str(topic_2nd+1)\n",
    "        \n",
    "        df_2nd_tmp = df_1st_tmp[df_1st_tmp['second_level_topic'] == topic_2nd].copy()\n",
    "        \n",
    "        df_data_tmp = tm.prepare_for_modeling(data_path=\"\", model_type=\"LDA-KeyWords\",\n",
    "                                           params={\"TEXT_prepared_df\": df_2nd_tmp,\n",
    "                                                   \"save_LDA_dictionary_path\": save_dict_path,\n",
    "                                                   \"words_column\": \"all_key_words\"\n",
    "                                                   },\n",
    "                                           verbose=1)\n",
    "\n",
    "        df_3d_tmp = tm.train_model(model_type=\"LDA-KeyWords\",\n",
    "                                    params={\"num_topics\": 3,\n",
    "                                            \"LDA_prepared_df\": df_data_tmp,\n",
    "                                            \"LDA_dictionary_path\": save_dict_path,\n",
    "                                            \"save_LDA_model_path\": save_LDA_model_path,\n",
    "                                            },\n",
    "                                    verbose=1)\n",
    "\n",
    "        df_3d_tmp['third_level_topic'] = df_3d_tmp['top_topic']\n",
    "        df_3d_tmp['third_level_topic_proba'] = df_3d_tmp['top_topic_proba']\n",
    "        #print(df_3d_tmp['second_level_topic'].value_counts().sort_index())\n",
    "\n",
    "        df_3d_tmp = df_3d_tmp.drop(columns=['doc2bow',\n",
    "                                               'infered_topics', 'top_topic', 'top_topic_proba'])\n",
    "        list_dfs.append(df_3d_tmp)\n",
    "        #value counts of THIRD level topics\n",
    "        print(\"Value counts of THIRD level topics:\")\n",
    "        print(df_3d_tmp['third_level_topic'].value_counts().sort_index())\n",
    "    print(\"#\"*50)\n",
    "finish = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of gettig Third level topics in minutes: 10.32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['date', 'author', 'title', 'url', 'section', 'publication',\n",
       "       'first_10_sents', 'list_of_first_10_sents', 'list_of_verb_lemmas',\n",
       "       'noun_phrases', 'list_of_nouns', 'list_of_lemmas', 'ID',\n",
       "       'group_level_1', 'group_level_2', 'group_level_3', 'all_words',\n",
       "       'all_key_words', 'first_level_topic', 'first_level_topic_proba',\n",
       "       'second_level_topic', 'second_level_topic_proba', 'third_level_topic',\n",
       "       'third_level_topic_proba'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Time of gettig Third level topics in minutes:\", round((finish-start)/60,2))\n",
    "df_third_level = pd.concat(list_dfs)\n",
    "df_third_level.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_third_level.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Topics (as a most frequent key-word in the cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tutorialspoint.com/gensim/gensim_creating_tf_idf_matrix.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pprint\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_level_topic</th>\n",
       "      <th>second_level_topic</th>\n",
       "      <th>third_level_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_level_topic  second_level_topic  third_level_topic\n",
       "0                  0                   0                  0\n",
       "1                  0                   0                  1\n",
       "2                  0                   0                  2\n",
       "3                  0                   1                  0\n",
       "4                  0                   1                  1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics = df_result.groupby(['first_level_topic', 'second_level_topic', 'third_level_topic'])['section'].count()\n",
    "df_topics = df_topics.reset_index()\n",
    "del df_topics['section']\n",
    "\n",
    "print(df_topics.shape)\n",
    "df_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_level_topic</th>\n",
       "      <th>second_level_topic</th>\n",
       "      <th>third_level_topic</th>\n",
       "      <th>first_level_topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hard seltzer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>hard seltzer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>hard seltzer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hard seltzer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>hard seltzer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_level_topic  second_level_topic  third_level_topic  \\\n",
       "0                  0                   0                  0   \n",
       "1                  0                   0                  1   \n",
       "2                  0                   0                  2   \n",
       "3                  0                   1                  0   \n",
       "4                  0                   1                  1   \n",
       "\n",
       "  first_level_topic_name  \n",
       "0           hard seltzer  \n",
       "1           hard seltzer  \n",
       "2           hard seltzer  \n",
       "3           hard seltzer  \n",
       "4           hard seltzer  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get first level topic names\n",
    "s = df_result.groupby('first_level_topic')['noun_phrases'].sum()\n",
    "word_lists_by_topic = list(s)\n",
    "\n",
    "dictionary = corpora.Dictionary()\n",
    "BoW_corpus = [dictionary.doc2bow(w_list, allow_update=True) for w_list in word_lists_by_topic]\n",
    "tfidf = models.TfidfModel(BoW_corpus, smartirs='ntc')\n",
    "\n",
    "topic_names_list = []\n",
    "for doc in tfidf[BoW_corpus]:\n",
    "    l = [(dictionary[id], np.around(freq,4)) for id, freq in doc]\n",
    "    #get a word with 3d highest tfidf score\n",
    "    w = sorted(l, key=lambda tup: tup[1], reverse=True)[3][0]\n",
    "    #print(w)\n",
    "    topic_names_list.append(w)\n",
    "    \n",
    "df_first_l_topics = pd.DataFrame({\"first_level_topic\": list(range(len(topic_names_list))),\n",
    "                                  \"first_level_topic_name\": topic_names_list\n",
    "                                 })\n",
    "df_topics = df_topics.merge(df_first_l_topics, on='first_level_topic', how='inner')\n",
    "df_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f&amp;s_topics</th>\n",
       "      <th>second_level_topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|0</td>\n",
       "      <td>dl1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0|1</td>\n",
       "      <td>arup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0|2</td>\n",
       "      <td>fanfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0|3</td>\n",
       "      <td>white claw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0|4</td>\n",
       "      <td>wouldbe journalist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  f&s_topics second_level_topic_name\n",
       "0        0|0                  dl1850\n",
       "1        0|1                    arup\n",
       "2        0|2              fanfiction\n",
       "3        0|3              white claw\n",
       "4        0|4      wouldbe journalist"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get second level topic names\n",
    "df_result['f&s_topics'] = df_result['first_level_topic'].apply(str) + \"|\" + \\\n",
    "                          df_result['second_level_topic'].apply(str)\n",
    "s = df_result.groupby('f&s_topics')['noun_phrases'].sum()\n",
    "word_lists_by_topic = list(s)\n",
    "s = s.reset_index()\n",
    "\n",
    "dictionary = corpora.Dictionary()\n",
    "BoW_corpus = [dictionary.doc2bow(w_list, allow_update=True) for w_list in word_lists_by_topic]\n",
    "tfidf = models.TfidfModel(BoW_corpus, smartirs='ntc')\n",
    "\n",
    "topic_names_list = []\n",
    "for doc in tfidf[BoW_corpus]:\n",
    "    l = [(dictionary[id], np.around(freq,4)) for id, freq in doc]\n",
    "    #get a word with 3d highest tfidf score\n",
    "    w = sorted(l, key=lambda tup: tup[1], reverse=True)[3][0]\n",
    "    #print(w)\n",
    "    topic_names_list.append(w)\n",
    "    \n",
    "df_second_l_topics = pd.DataFrame({\"f&s_topics\": s['f&s_topics'],\n",
    "                                  \"second_level_topic_name\": topic_names_list\n",
    "                                 })\n",
    "print(df_second_l_topics.shape)\n",
    "df_second_l_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_level_topic</th>\n",
       "      <th>second_level_topic</th>\n",
       "      <th>third_level_topic</th>\n",
       "      <th>first_level_topic_name</th>\n",
       "      <th>f&amp;s_topics</th>\n",
       "      <th>second_level_topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>0|0</td>\n",
       "      <td>dl1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>0|0</td>\n",
       "      <td>dl1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>0|0</td>\n",
       "      <td>dl1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>0|1</td>\n",
       "      <td>arup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>0|1</td>\n",
       "      <td>arup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_level_topic  second_level_topic  third_level_topic  \\\n",
       "0                  0                   0                  0   \n",
       "1                  0                   0                  1   \n",
       "2                  0                   0                  2   \n",
       "3                  0                   1                  0   \n",
       "4                  0                   1                  1   \n",
       "\n",
       "  first_level_topic_name f&s_topics second_level_topic_name  \n",
       "0           hard seltzer        0|0                  dl1850  \n",
       "1           hard seltzer        0|0                  dl1850  \n",
       "2           hard seltzer        0|0                  dl1850  \n",
       "3           hard seltzer        0|1                    arup  \n",
       "4           hard seltzer        0|1                    arup  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics['f&s_topics'] = df_topics['first_level_topic'].apply(str) + \"|\" + \\\n",
    "                          df_topics['second_level_topic'].apply(str)\n",
    "df_topics = df_topics.merge(df_second_l_topics, on='f&s_topics', how='inner')\n",
    "df_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f&amp;s&amp;th_topics</th>\n",
       "      <th>third_level_topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|0|0</td>\n",
       "      <td>kleinman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0|0|1</td>\n",
       "      <td>national sandwich day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0|0|2</td>\n",
       "      <td>momotombo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0|1|0</td>\n",
       "      <td>bub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0|1|1</td>\n",
       "      <td>xia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  f&s&th_topics third_level_topic_name\n",
       "0         0|0|0               kleinman\n",
       "1         0|0|1  national sandwich day\n",
       "2         0|0|2              momotombo\n",
       "3         0|1|0                    bub\n",
       "4         0|1|1                    xia"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get third level topic names\n",
    "df_result['f&s&th_topics'] = df_result['first_level_topic'].apply(str) + \"|\" + \\\n",
    "                          df_result['second_level_topic'].apply(str) + \"|\" + \\\n",
    "                          df_result['third_level_topic'].apply(str)\n",
    "s = df_result.groupby('f&s&th_topics')['noun_phrases'].sum()\n",
    "word_lists_by_topic = list(s)\n",
    "s = s.reset_index()\n",
    "\n",
    "dictionary = corpora.Dictionary()\n",
    "BoW_corpus = [dictionary.doc2bow(w_list, allow_update=True) for w_list in word_lists_by_topic]\n",
    "tfidf = models.TfidfModel(BoW_corpus, smartirs='ntc')\n",
    "\n",
    "topic_names_list = []\n",
    "for doc in tfidf[BoW_corpus]:\n",
    "    l = [(dictionary[id], np.around(freq,4)) for id, freq in doc]\n",
    "    #get a word with 3d highest tfidf score\n",
    "    w = sorted(l, key=lambda tup: tup[1], reverse=True)[3][0]\n",
    "    #print(w)\n",
    "    topic_names_list.append(w)\n",
    "    \n",
    "df_third_l_topics = pd.DataFrame({\"f&s&th_topics\": s['f&s&th_topics'],\n",
    "                                  \"third_level_topic_name\": topic_names_list\n",
    "                                 })\n",
    "print(df_third_l_topics.shape)\n",
    "df_third_l_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_level_topic</th>\n",
       "      <th>second_level_topic</th>\n",
       "      <th>third_level_topic</th>\n",
       "      <th>first_level_topic_name</th>\n",
       "      <th>f&amp;s_topics</th>\n",
       "      <th>second_level_topic_name</th>\n",
       "      <th>f&amp;s&amp;th_topics</th>\n",
       "      <th>third_level_topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>0|0</td>\n",
       "      <td>dl1850</td>\n",
       "      <td>0|0|0</td>\n",
       "      <td>kleinman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>0|0</td>\n",
       "      <td>dl1850</td>\n",
       "      <td>0|0|1</td>\n",
       "      <td>national sandwich day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>0|0</td>\n",
       "      <td>dl1850</td>\n",
       "      <td>0|0|2</td>\n",
       "      <td>momotombo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>0|1</td>\n",
       "      <td>arup</td>\n",
       "      <td>0|1|0</td>\n",
       "      <td>bub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>0|1</td>\n",
       "      <td>arup</td>\n",
       "      <td>0|1|1</td>\n",
       "      <td>xia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_level_topic  second_level_topic  third_level_topic  \\\n",
       "0                  0                   0                  0   \n",
       "1                  0                   0                  1   \n",
       "2                  0                   0                  2   \n",
       "3                  0                   1                  0   \n",
       "4                  0                   1                  1   \n",
       "\n",
       "  first_level_topic_name f&s_topics second_level_topic_name f&s&th_topics  \\\n",
       "0           hard seltzer        0|0                  dl1850         0|0|0   \n",
       "1           hard seltzer        0|0                  dl1850         0|0|1   \n",
       "2           hard seltzer        0|0                  dl1850         0|0|2   \n",
       "3           hard seltzer        0|1                    arup         0|1|0   \n",
       "4           hard seltzer        0|1                    arup         0|1|1   \n",
       "\n",
       "  third_level_topic_name  \n",
       "0               kleinman  \n",
       "1  national sandwich day  \n",
       "2              momotombo  \n",
       "3                    bub  \n",
       "4                    xia  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics['f&s&th_topics'] = df_topics['first_level_topic'].apply(str) + \"|\" + \\\n",
    "                          df_topics['second_level_topic'].apply(str) + \"|\" + \\\n",
    "                          df_topics['third_level_topic'].apply(str)\n",
    "df_topics = df_topics.merge(df_third_l_topics, on='f&s&th_topics', how='inner')\n",
    "df_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 6) (150, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first_level_topic</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_level_topic_name</th>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>hard seltzer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_level_topic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_level_topic_name</th>\n",
       "      <td>dl1850</td>\n",
       "      <td>dl1850</td>\n",
       "      <td>dl1850</td>\n",
       "      <td>arup</td>\n",
       "      <td>arup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_level_topic</th>\n",
       "      <td>0.0.0</td>\n",
       "      <td>0.0.1</td>\n",
       "      <td>0.0.2</td>\n",
       "      <td>0.1.0</td>\n",
       "      <td>0.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_level_topic_name</th>\n",
       "      <td>kleinman</td>\n",
       "      <td>national sandwich day</td>\n",
       "      <td>momotombo</td>\n",
       "      <td>bub</td>\n",
       "      <td>xia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0                      1             2  \\\n",
       "first_level_topic                   0                      0             0   \n",
       "first_level_topic_name   hard seltzer           hard seltzer  hard seltzer   \n",
       "second_level_topic                0.0                    0.0           0.0   \n",
       "second_level_topic_name        dl1850                 dl1850        dl1850   \n",
       "third_level_topic               0.0.0                  0.0.1         0.0.2   \n",
       "third_level_topic_name       kleinman  national sandwich day     momotombo   \n",
       "\n",
       "                                    3             4  \n",
       "first_level_topic                   0             0  \n",
       "first_level_topic_name   hard seltzer  hard seltzer  \n",
       "second_level_topic                0.1           0.1  \n",
       "second_level_topic_name          arup          arup  \n",
       "third_level_topic               0.1.0         0.1.1  \n",
       "third_level_topic_name            bub           xia  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\n",
    "    'first_level_topic','first_level_topic_name',\n",
    "    'second_level_topic','second_level_topic_name',\n",
    "    'third_level_topic', 'third_level_topic_name'\n",
    "   ]\n",
    "df_lda_topics = df_topics[columns].drop_duplicates()\n",
    "print(df_lda_topics.shape, df_topics.shape)\n",
    "df_lda_topics['second_level_topic'] = df_lda_topics['first_level_topic'].apply(str) + '.' + df_lda_topics['second_level_topic'].apply(str)\n",
    "df_lda_topics['third_level_topic'] = df_lda_topics['second_level_topic'].apply(str) + '.' + df_lda_topics['third_level_topic'].apply(str)\n",
    "df_lda_topics.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/lda_keywords/topics.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(df_lda_topics, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "      <th>3000</th>\n",
       "      <th>4000</th>\n",
       "      <th>5000</th>\n",
       "      <th>6000</th>\n",
       "      <th>7000</th>\n",
       "      <th>8000</th>\n",
       "      <th>9000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <td>Economist</td>\n",
       "      <td>Wired</td>\n",
       "      <td>Economist</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Economist</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Wired</td>\n",
       "      <td>Wired</td>\n",
       "      <td>CNN</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section</th>\n",
       "      <td>business</td>\n",
       "      <td>science</td>\n",
       "      <td>finance-and-economics</td>\n",
       "      <td>business</td>\n",
       "      <td>finance-and-economics</td>\n",
       "      <td>movies</td>\n",
       "      <td>culture</td>\n",
       "      <td>culture</td>\n",
       "      <td>health</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_level_topic_name</th>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>daily dispatch</td>\n",
       "      <td>daily dispatch</td>\n",
       "      <td>daily dispatch</td>\n",
       "      <td>huawei equipment</td>\n",
       "      <td>huawei equipment</td>\n",
       "      <td>huawei equipment</td>\n",
       "      <td>prevention</td>\n",
       "      <td>prevention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_level_topic_name</th>\n",
       "      <td>dl1850</td>\n",
       "      <td>wouldbe journalist</td>\n",
       "      <td>inflation</td>\n",
       "      <td>financial crisis</td>\n",
       "      <td>tariff</td>\n",
       "      <td>star wars</td>\n",
       "      <td>huawei equipment</td>\n",
       "      <td>anias mcdonald</td>\n",
       "      <td>centers</td>\n",
       "      <td>centers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_level_topic_name</th>\n",
       "      <td>momotombo</td>\n",
       "      <td>salvation army</td>\n",
       "      <td>alibaba</td>\n",
       "      <td>central bank</td>\n",
       "      <td>spector</td>\n",
       "      <td>episode ix</td>\n",
       "      <td>mariee</td>\n",
       "      <td>nicole</td>\n",
       "      <td>air pollution</td>\n",
       "      <td>cardiovascular disease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0                   1000  \\\n",
       "publication                 Economist               Wired   \n",
       "section                      business             science   \n",
       "first_level_topic_name   hard seltzer        hard seltzer   \n",
       "second_level_topic_name        dl1850  wouldbe journalist   \n",
       "third_level_topic_name      momotombo      salvation army   \n",
       "\n",
       "                                          2000              3000  \\\n",
       "publication                          Economist               CNN   \n",
       "section                  finance-and-economics          business   \n",
       "first_level_topic_name          daily dispatch    daily dispatch   \n",
       "second_level_topic_name              inflation  financial crisis   \n",
       "third_level_topic_name                 alibaba      central bank   \n",
       "\n",
       "                                          4000              5000  \\\n",
       "publication                          Economist               CNN   \n",
       "section                  finance-and-economics            movies   \n",
       "first_level_topic_name          daily dispatch  huawei equipment   \n",
       "second_level_topic_name                 tariff         star wars   \n",
       "third_level_topic_name                 spector        episode ix   \n",
       "\n",
       "                                     6000              7000           8000  \\\n",
       "publication                         Wired             Wired            CNN   \n",
       "section                           culture           culture         health   \n",
       "first_level_topic_name   huawei equipment  huawei equipment     prevention   \n",
       "second_level_topic_name  huawei equipment    anias mcdonald        centers   \n",
       "third_level_topic_name             mariee            nicole  air pollution   \n",
       "\n",
       "                                           9000  \n",
       "publication                                 CNN  \n",
       "section                                  health  \n",
       "first_level_topic_name               prevention  \n",
       "second_level_topic_name                 centers  \n",
       "third_level_topic_name   cardiovascular disease  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_result.copy()\n",
    "\n",
    "df = df.merge(df_first_l_topics, on='first_level_topic', how='inner')\n",
    "df = df.merge(df_second_l_topics, on='f&s_topics', how='inner')\n",
    "df = df.merge(df_third_l_topics, on='f&s&th_topics', how='inner')\n",
    "\n",
    "df[['publication', \n",
    "    'section',\n",
    "    'first_level_topic_name',\n",
    "    'second_level_topic_name',\n",
    "    'third_level_topic_name'\n",
    "   ]].iloc[::1000].head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>5000</th>\n",
       "      <th>10000</th>\n",
       "      <th>15000</th>\n",
       "      <th>20000</th>\n",
       "      <th>25000</th>\n",
       "      <th>30000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <td>Economist</td>\n",
       "      <td>CNN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Wired</td>\n",
       "      <td>Wired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section</th>\n",
       "      <td>business</td>\n",
       "      <td>movies</td>\n",
       "      <td>health</td>\n",
       "      <td>health</td>\n",
       "      <td>business</td>\n",
       "      <td>science</td>\n",
       "      <td>gear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_level_topic_name</th>\n",
       "      <td>hard seltzer</td>\n",
       "      <td>huawei equipment</td>\n",
       "      <td>prevention</td>\n",
       "      <td>prevention</td>\n",
       "      <td>boeing ba</td>\n",
       "      <td>political ad</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_level_topic_name</th>\n",
       "      <td>dl1850</td>\n",
       "      <td>star wars</td>\n",
       "      <td>disease control</td>\n",
       "      <td>zika</td>\n",
       "      <td>rocket</td>\n",
       "      <td>hacker</td>\n",
       "      <td>mr pawlowski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_level_topic_name</th>\n",
       "      <td>momotombo</td>\n",
       "      <td>episode ix</td>\n",
       "      <td>vaccine</td>\n",
       "      <td>drug</td>\n",
       "      <td>small satellite</td>\n",
       "      <td>account</td>\n",
       "      <td>myhrvold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0                 5000             10000  \\\n",
       "publication                 Economist               CNN              CNN   \n",
       "section                      business            movies           health   \n",
       "first_level_topic_name   hard seltzer  huawei equipment       prevention   \n",
       "second_level_topic_name        dl1850         star wars  disease control   \n",
       "third_level_topic_name      momotombo        episode ix          vaccine   \n",
       "\n",
       "                              15000            20000         25000  \\\n",
       "publication                     CNN              CNN         Wired   \n",
       "section                      health         business       science   \n",
       "first_level_topic_name   prevention        boeing ba  political ad   \n",
       "second_level_topic_name        zika           rocket        hacker   \n",
       "third_level_topic_name         drug  small satellite       account   \n",
       "\n",
       "                                30000  \n",
       "publication                     Wired  \n",
       "section                          gear  \n",
       "first_level_topic_name         people  \n",
       "second_level_topic_name  mr pawlowski  \n",
       "third_level_topic_name       myhrvold  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['publication', \n",
    "    'section',\n",
    "    'first_level_topic_name',\n",
    "    'second_level_topic_name',\n",
    "    'third_level_topic_name'\n",
    "   ]].iloc[::5000].head(10).T"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GLG - 3_step - Assigning Text Groups.ipynb",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
