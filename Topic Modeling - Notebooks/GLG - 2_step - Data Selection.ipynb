{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting data for model training and testing\n",
    "- Since GLG is interested in short text topic modeling (abstracts from client request), only part of news text is needed\n",
    "- Test data is taken from well-defined sections to see if all news from those sect6ions go at least to first level cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tatiana/opt/anaconda3/lib/python3.7/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# data processing libraries\n",
    "import pandas as pd\n",
    "\n",
    "# display wider columns in pandas data frames where necessary\n",
    "pd.set_option('max_colwidth',150)\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# supporting libraries\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file location of the data\n",
    "input_folder = './data/'\n",
    "output_folder = './transition_files/'\n",
    "\n",
    "file_name = 'all-the-news-2-1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and selecting first few paragraphs (10 sentences) for selected publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tatiana/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (1,3,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2688879, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>2016-12-09 18:31:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>Lee Drutman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>We should take concerns about the health of liberal democracy seriously</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <td>This post is part of Polyarchy, an independent blog produced by the political reform program at New America, a Washington think tank devoted to de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>https://www.vox.com/polyarchy/2016/12/9/13898340/democracy-warning-signs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <td>Vox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                  0\n",
       "Unnamed: 0                                                                                                                                                        0\n",
       "Unnamed: 0.1                                                                                                                                                      0\n",
       "date                                                                                                                                            2016-12-09 18:31:00\n",
       "year                                                                                                                                                           2016\n",
       "month                                                                                                                                                            12\n",
       "day                                                                                                                                                               9\n",
       "author                                                                                                                                                  Lee Drutman\n",
       "title                                                                                       We should take concerns about the health of liberal democracy seriously\n",
       "article       This post is part of Polyarchy, an independent blog produced by the political reform program at New America, a Washington think tank devoted to de...\n",
       "url                                                                                        https://www.vox.com/polyarchy/2016/12/9/13898340/democracy-warning-signs\n",
       "section                                                                                                                                                         NaN\n",
       "publication                                                                                                                                                     Vox"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df_data = pd.read_csv(input_folder + file_name, #file location\n",
    "                      encoding = \"ISO-8859-1\", #deal with texts in different formats\n",
    "                     )\n",
    "\n",
    "# display first row of the data frame\n",
    "print(df_data.shape)\n",
    "df_data.head(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1660535, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select ONLY data with specified section and publication and non-duplicated texts of article\n",
    "df_data['publication'] = df_data['publication'].fillna(\"\")\n",
    "df_data = df_data[df_data['publication'].apply(len)>0]\n",
    "\n",
    "df_data['section'] = df_data['section'].fillna(\"\")\n",
    "df_data = df_data[df_data['section'].apply(len)>0]\n",
    "\n",
    "df_data['article'] = df_data['article'].fillna(\"\")\n",
    "df_data = df_data[df_data['article'].apply(len)>0]\n",
    "df_data = df_data.drop_duplicates('article')\n",
    "\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNBC</th>\n",
       "      <td>634</td>\n",
       "      <td>191185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>63</td>\n",
       "      <td>124659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economist</th>\n",
       "      <td>46</td>\n",
       "      <td>23050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fox News</th>\n",
       "      <td>670</td>\n",
       "      <td>20130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gizmodo</th>\n",
       "      <td>78</td>\n",
       "      <td>18214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Yorker</th>\n",
       "      <td>1</td>\n",
       "      <td>4644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>People</th>\n",
       "      <td>35</td>\n",
       "      <td>133766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reuters</th>\n",
       "      <td>224</td>\n",
       "      <td>734147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The New York Times</th>\n",
       "      <td>3774</td>\n",
       "      <td>240107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Verge</th>\n",
       "      <td>148</td>\n",
       "      <td>50201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vice</th>\n",
       "      <td>1324</td>\n",
       "      <td>100347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington Post</th>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wired</th>\n",
       "      <td>28</td>\n",
       "      <td>20057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    section  article\n",
       "publication                         \n",
       "CNBC                    634   191185\n",
       "CNN                      63   124659\n",
       "Economist                46    23050\n",
       "Fox News                670    20130\n",
       "Gizmodo                  78    18214\n",
       "New Yorker                1     4644\n",
       "People                   35   133766\n",
       "Reuters                 224   734147\n",
       "The New York Times     3774   240107\n",
       "The Verge               148    50201\n",
       "Vice                   1324   100347\n",
       "Washington Post           5       28\n",
       "Wired                    28    20057"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Publications in the data\n",
    "print('Number of unique values:')\n",
    "df = df_data.groupby('publication')[['section', 'article']].nunique()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article',\n",
       " 'artificial-intelligence',\n",
       " 'backchannel',\n",
       " 'business',\n",
       " 'culture',\n",
       " 'deals',\n",
       " 'design',\n",
       " 'environment',\n",
       " 'gadget-lab-podcast',\n",
       " 'gadgetlab',\n",
       " 'gear',\n",
       " 'ideas',\n",
       " 'magazine',\n",
       " 'music',\n",
       " 'national-affairs',\n",
       " 'opinion',\n",
       " 'outdoor',\n",
       " 'phones',\n",
       " 'photo',\n",
       " 'physics-math',\n",
       " 'privacy',\n",
       " 'reviews',\n",
       " 'science',\n",
       " 'security',\n",
       " 'social-media',\n",
       " 'transportation',\n",
       " 'trends',\n",
       " 'uncategorized'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check each publication\n",
    "set(df_data[df_data['publication'] == \"Wired\"]['section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "section       250\n",
      "article    319746\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>63</td>\n",
       "      <td>124659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economist</th>\n",
       "      <td>46</td>\n",
       "      <td>23050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gizmodo</th>\n",
       "      <td>78</td>\n",
       "      <td>18214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>People</th>\n",
       "      <td>35</td>\n",
       "      <td>133766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wired</th>\n",
       "      <td>28</td>\n",
       "      <td>20057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             section  article\n",
       "publication                  \n",
       "CNN               63   124659\n",
       "Economist         46    23050\n",
       "Gizmodo           78    18214\n",
       "People            35   133766\n",
       "Wired             28    20057"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only publications with more than 10 sections and less than 100\n",
    "df=df[(df['section'] > 10) & (df['section'] < 100)]\n",
    "print(df.sum())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN', 'Economist', 'Gizmodo', 'People', 'Wired']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_publications = list(df.index)\n",
    "selected_publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319746, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_data[df_data['publication'].isin(selected_publications)]\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306365, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean text\n",
    "df_data['article'] = df_data['article'].str.replace(r\"[^A-Za-z0-9//-/.,!?:; ]\",'', regex=True)\n",
    "\n",
    "#select texts that have at least 500 but no more than 10000 symbols\n",
    "df_data['text_length'] = df_data['article'].fillna(\"\").apply(len)\n",
    "df_data = df_data[df_data['text_length'] >= 500]\n",
    "df_data = df_data[df_data['text_length'] < 10000]\n",
    "\n",
    "# cut text to have no more than 1500 symbols\n",
    "df_data['article'] = df_data['article'].str[:1500]\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      229.000000\n",
       "mean      1337.838428\n",
       "std       4400.854165\n",
       "min          1.000000\n",
       "1%           1.000000\n",
       "25%          4.000000\n",
       "50%         50.000000\n",
       "75%        819.000000\n",
       "99%      18521.880000\n",
       "max      50665.000000\n",
       "Name: section, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking number of articles per section\n",
    "s = df_data['section'].value_counts()\n",
    "s.describe(percentiles=[0.01,0.25,0.5,0.75,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306365, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['section_articles_count'] = df_data.groupby('section')['url'].transform(\"count\")\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188479, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting articles from sections with at least 1000 articles but not more than 15000\n",
    "df_data = df_data[(df_data['section_articles_count'] > 1000) &\n",
    "                    (df_data['section_articles_count'] < 15000) \n",
    "                   ]\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movies                    12741\n",
       "style                     11487\n",
       "crime                     10988\n",
       "health                    10913\n",
       "music                      9942\n",
       "opinions                   9441\n",
       "entertainment              9431\n",
       "celebrity                  9148\n",
       "parents                    6948\n",
       "business                   6930\n",
       "asia                       6374\n",
       "human-interest             5746\n",
       "royals                     5504\n",
       "pets                       5104\n",
       "food                       4400\n",
       "sports                     3945\n",
       "home                       3419\n",
       "culture                    3247\n",
       "science                    2911\n",
       "world                      2867\n",
       "bodies                     2758\n",
       "middleeast                 2696\n",
       "tech                       2631\n",
       "News                       2409\n",
       "babies                     2203\n",
       "africa                     2139\n",
       "gear                       2108\n",
       "Sploid                     2041\n",
       "security                   1840\n",
       "investing                  1822\n",
       "country                    1818\n",
       "transportation             1666\n",
       "britain                    1651\n",
       "finance-and-economics      1648\n",
       "Space                      1641\n",
       "europe                     1548\n",
       "americas                   1461\n",
       "Privacy and Security       1404\n",
       "united-states              1326\n",
       "media                      1313\n",
       "middle-east-and-africa     1266\n",
       "Health                     1193\n",
       "awards                     1126\n",
       "Apple                      1095\n",
       "app-news-section           1061\n",
       "graphic-detail             1061\n",
       "books-and-arts             1039\n",
       "leaders                    1029\n",
       "Name: section, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#section names\n",
    "df_data['section'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119138, 14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete too wide or too nerrow topics\n",
    "delete_sections = [\"bodies\", \"News\", \"Sploid\", \"media\", \"investing\", \"human-interest\",\n",
    "                   \"country\", \"britain\", \"europe\", \"united-states\", \"americas\",\n",
    "                   \"middle-east-and-africa\", \"africa\", \"asia\", \"world\", \"home\", \"middleeast\",\n",
    "                   \"awards\", \"Apple\", \"graphic-detail\", \"books-and-arts\", \"opinions\",\n",
    "                   \"leaders\", \"app-news-section\", \"Privacy and Security\", \"entertainment\"\n",
    "                  ]\n",
    "df_data = df_data[df_data['section'].isin(delete_sections) == False]\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movies                   12741\n",
       "style                    11487\n",
       "crime                    10988\n",
       "health                   10913\n",
       "music                     9942\n",
       "celebrity                 9148\n",
       "parents                   6948\n",
       "business                  6930\n",
       "royals                    5504\n",
       "pets                      5104\n",
       "food                      4400\n",
       "sports                    3945\n",
       "culture                   3247\n",
       "science                   2911\n",
       "tech                      2631\n",
       "babies                    2203\n",
       "gear                      2108\n",
       "security                  1840\n",
       "transportation            1666\n",
       "finance-and-economics     1648\n",
       "Space                     1641\n",
       "Health                    1193\n",
       "Name: section, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selected section names\n",
    "df_data['section'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>6</td>\n",
       "      <td>13762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economist</th>\n",
       "      <td>2</td>\n",
       "      <td>3149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gizmodo</th>\n",
       "      <td>2</td>\n",
       "      <td>2834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>People</th>\n",
       "      <td>13</td>\n",
       "      <td>85151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wired</th>\n",
       "      <td>7</td>\n",
       "      <td>14230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             section  article\n",
       "publication                  \n",
       "CNN                6    13762\n",
       "Economist          2     3149\n",
       "Gizmodo            2     2834\n",
       "People            13    85151\n",
       "Wired              7    14230"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Publications in the selected data\n",
    "print('Number of unique values:')\n",
    "df = df_data.groupby('publication')[['section', 'article']].nunique()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 50001 0\n",
      "1 50001 50000\n",
      "2 19138 100000\n"
     ]
    }
   ],
   "source": [
    "# split the data on sub-samples of 50,000 records each \n",
    "# and save for next steps\n",
    "k = 0\n",
    "batch_size = 50000\n",
    "\n",
    "for k in range(3):\n",
    "    df_part = df_data.loc[k * batch_size: (k+1) * batch_size,:]\n",
    "    print(k, len(df_part), df_part.index[0])\n",
    "    with open(output_folder + 'data_part_'+str(k)+'.pickle', 'wb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(df_part, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting first few paragraphs (10 sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "CPU times: user 19min 52s, sys: 2.83 s, total: 19min 55s\n",
      "Wall time: 19min 55s\n",
      "==================================================\n",
      "1\n",
      "CPU times: user 19min 41s, sys: 1.75 s, total: 19min 43s\n",
      "Wall time: 19min 43s\n",
      "==================================================\n",
      "2\n",
      "CPU times: user 6min 47s, sys: 456 ms, total: 6min 47s\n",
      "Wall time: 6min 47s\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for k in range(3):\n",
    "    file_name = 'data_part_'+str(k)+'.pickle'\n",
    "\n",
    "    # load data\n",
    "    with open(output_folder + file_name, 'rb') as f:\n",
    "        # The protocol version used is detected automatically, so we do not\n",
    "        # have to specify it.\n",
    "        df_data = pickle.load(f)\n",
    "\n",
    "    #get spaCy doc\n",
    "    print(k)\n",
    "    %time df_data['spacy_doc'] = df_data['article'].apply(lambda x: nlp(x))\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    #delete text of article\n",
    "    del df_data['article']\n",
    "    \n",
    "    #save batch as pickle\n",
    "    with open(output_folder + 'spacy_doc_' +str(k)+ '.pickle', 'wb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(df_data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Test and Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean noun phrases from stop-words\n",
    "def clean_NPs(np):\n",
    "    tmp_no_stop_words = [w for w in np if w.is_stop==False]\n",
    "\n",
    "    #make only last word as lemma\n",
    "    if len(tmp_no_stop_words)>0:\n",
    "        tmp_lemmas = [w.text for w in tmp_no_stop_words[:-1]] + [tmp_no_stop_words[-1].lemma_]\n",
    "    else:\n",
    "        tmp_lemmas = []\n",
    "\n",
    "    tmp_atleast_one_alpha = [w for w in tmp_lemmas if len(re.sub(r\"\\d|\\W\", \"\", w)) > 0]\n",
    "    tmp_result = [w for w in tmp_atleast_one_alpha if len(w)>0]\n",
    "    \n",
    "    return \" \".join(tmp_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy_doc_0.pickle\n",
      "spacy_doc_1.pickle\n",
      "spacy_doc_2.pickle\n"
     ]
    }
   ],
   "source": [
    "list_dfs = []\n",
    "\n",
    "for k in range(3):\n",
    "    file_name = 'spacy_doc_' +str(k)+ '.pickle'\n",
    "    print(file_name)\n",
    "\n",
    "    # load data\n",
    "    with open(output_folder + file_name, 'rb') as f:\n",
    "        # The protocol version used is detected automatically, so we do not\n",
    "        # have to specify it.\n",
    "        df_data = pickle.load(f)\n",
    "    \n",
    "    #select first 10 sentenses\n",
    "    df_data['first_10_sents'] = df_data['spacy_doc'].apply(lambda doc: list(doc.sents)[:10])\n",
    "    \n",
    "    #extract noun phrases from first 10 sentenses for cluster naming\n",
    "    df_data['list_of_nouns'] = df_data['first_10_sents'].apply(lambda sents: [word \n",
    "                                                                     for s in sents \n",
    "                                                                     for word in s if (word.is_stop==False) & \\\n",
    "                                                                                 (len(word.text)>2) & \\\n",
    "                                                                                 (word.is_alpha) & \\\n",
    "                                                                                 (word.pos_ == 'NOUN')])\n",
    "    #extract lemmas from first 10 sentenses for cluster naming\n",
    "    df_data['list_of_lemmas'] = df_data['first_10_sents'].apply(lambda sents: [word \n",
    "                                                         for s in sents \n",
    "                                                         for word in s if (word.is_stop==False) & \\\n",
    "                                                                     (len(word.text)>2) & \\\n",
    "                                                                     (word.is_alpha) & \\\n",
    "                                                                     (word.pos_ in ['NOUN', 'VERB', 'ADJ', 'ADV'])])\n",
    "    \n",
    "    \n",
    "    #extract lemmas from first 10 sentenses for cluster naming\n",
    "    df_data['list_of_verb_lemmas'] = df_data['first_10_sents'].apply(lambda sents: [word \n",
    "                                                         for s in sents \n",
    "                                                         for word in s if (word.is_stop==False) & \\\n",
    "                                                                     (len(word.text)>2) & \\\n",
    "                                                                     (word.is_alpha) & \\\n",
    "                                                                     (word.pos_ in ['VERB'])])\n",
    "    \n",
    "    #extract noun phrases from first 10 sentenses\n",
    "    df_data['noun_phrases'] = df_data['first_10_sents'].apply(lambda sents: [np \n",
    "                                                                             for s in sents \n",
    "                                                                             for np in s.noun_chunks])\n",
    "    \n",
    "    #delete stop-words (\"the\", \"a\", \"your\" etc.) and clean NPs\n",
    "    df_data['noun_phrases'] = df_data['noun_phrases'].apply(lambda NPs: [clean_NPs(np) for np in NPs])\n",
    "    df_data['noun_phrases'] = df_data['noun_phrases'].apply(lambda NPs: [np for np in NPs if len(np)>1])\n",
    "    \n",
    "    df_data['list_of_first_10_sents'] = df_data['first_10_sents'].apply(lambda l: [s.text for s in l])\n",
    "    df_data['first_10_sents'] = df_data['first_10_sents'].apply(lambda l: \" \".join([s.text for s in l]))\n",
    "\n",
    "    #delete 'spacy_doc' of article \n",
    "    #(it is used for LDA model but we need only text of first 10 sentenses for other models)\n",
    "    del df_data['spacy_doc']\n",
    "    \n",
    "    list_dfs.append(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119140, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Unnamed: 0', 'Unnamed: 0.1', 'date', 'year', 'month', 'day',\n",
       "       'author', 'title', 'url', 'section', 'publication', 'text_length',\n",
       "       'section_articles_count', 'first_10_sents', 'list_of_nouns',\n",
       "       'list_of_lemmas', 'list_of_verb_lemmas', 'noun_phrases',\n",
       "       'list_of_first_10_sents'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.concat(list_dfs)\n",
    "print(df_data.shape)\n",
    "df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Calling all foodies  get your royal rsums ready!, Queen Elizabethis looking for a kitchen porter, and the fulltime job comes with some dream perk...\n",
       "1    [Celebloved Stanley the giraffe is seemingly safe as two wildfires continue to devastate southern California, but animal rights critics are still ...\n",
       "2    [John Oliver has a special treat in store for the one of the last Blockbuster stores., Though the formerly popular video rental chain has been for...\n",
       "3    [Blake Lively has one of the mostshared celebrity manes on Pinterest., Well, at least according to the inspiration boards Im looking at., And shes...\n",
       "4    [Meghan King Edmonds knows how to put together a gorgeous space., Weeks after welcoming twin sons Hart King and Hayes Kingon June 5, the 33yearold...\n",
       "Name: list_of_first_10_sents, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['list_of_first_10_sents'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85158, 20)\n"
     ]
    }
   ],
   "source": [
    "#Save Test data (People articles)\n",
    "df_test = df_data[df_data['publication'] == \"People\"]\n",
    "print(df_test.shape)\n",
    "df_test[[\"date\", 'author', \n",
    "         'title', 'url', \n",
    "         'section', 'publication',\n",
    "         'first_10_sents','list_of_first_10_sents', \n",
    "         'list_of_verb_lemmas', 'noun_phrases', 'list_of_nouns','list_of_lemmas'\n",
    "        ]].to_csv(output_folder + \"test.tsv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33982, 20)\n"
     ]
    }
   ],
   "source": [
    "#Save Train data (all but People articles)\n",
    "df_train = df_data[df_data['publication'] != \"People\"]\n",
    "print(df_train.shape)\n",
    "df_train[[\"date\", 'author', \n",
    "         'title', 'url', \n",
    "         'section', 'publication',\n",
    "         'first_10_sents','list_of_first_10_sents', \n",
    "         'list_of_verb_lemmas', 'noun_phrases', 'list_of_nouns','list_of_lemmas'\n",
    "         ]].to_csv(output_folder + \"train.tsv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data articles by publications:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "publication\n",
       "CNN          13763\n",
       "Economist     3153\n",
       "Gizmodo       2834\n",
       "Wired        14232\n",
       "Name: first_10_sents, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#publications in Train dataset\n",
    "print(\"Train data articles by publications:\")\n",
    "df_train.groupby('publication')['first_10_sents'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "health                   8237\n",
       "business                 6930\n",
       "culture                  3247\n",
       "science                  2911\n",
       "tech                     2527\n",
       "gear                     2108\n",
       "security                 1841\n",
       "transportation           1666\n",
       "finance-and-economics    1648\n",
       "Space                    1641\n",
       "Health                   1193\n",
       "movies                     31\n",
       "music                       1\n",
       "style                       1\n",
       "Name: section, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selected section names\n",
    "df_train['section'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
